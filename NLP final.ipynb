{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "oL6AqKyPeam7",
    "outputId": "fd2b033c-0130-4d0f-fe78-71fea226f3ae"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import requests\n",
    "import hashlib\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlparse\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ==== BƯỚC 1: Đọc toàn bộ CSV từ thư mục ====\n",
    "def read_all_csv_in_folder(folder_path):\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    dfs = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# ==== BƯỚC 2: Tiền xử lý dữ liệu ====\n",
    "def preprocess_df(df):\n",
    "    df = df[['article_url', 'article_title', 'article_description', 'clickbait_level']].copy()\n",
    "    df['label'] = df['clickbait_level'].apply(lambda x: 0 if x in [1, 2] else 1)\n",
    "    return df\n",
    "\n",
    "# ==== BƯỚC 3: Tạo tên file ảnh duy nhất ====\n",
    "def safe_filename_from_url(url):\n",
    "    h = hashlib.md5(url.encode()).hexdigest()\n",
    "    return f\"{h}.jpg\"\n",
    "\n",
    "# ==== BƯỚC 4: Crawl thumbnail từ HTML ====\n",
    "def extract_thumbnail_from_html(url):\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(url, headers=headers, timeout=3)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        og_image = soup.find(\"meta\", property=\"og:image\")\n",
    "        if og_image and og_image.get(\"content\"):\n",
    "            return og_image[\"content\"]\n",
    "        first_img = soup.find(\"img\")\n",
    "        if first_img and first_img.get(\"src\"):\n",
    "            return first_img[\"src\"]\n",
    "    except Exception as e:\n",
    "        print(f\"[Thumbnail HTML Error] {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "# ==== BƯỚC 5: Tải và resize ảnh ====\n",
    "def download_and_resize_image(image_url, save_dir):\n",
    "    try:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        response = requests.get(image_url, timeout=3)\n",
    "        response.raise_for_status()\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img = img.resize((200, 200))\n",
    "        filename = safe_filename_from_url(image_url)\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        img.save(save_path, format=\"JPEG\")\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        print(f\"[Download Error] {image_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==== BƯỚC 6: Worker đa luồng cho từng URL ====\n",
    "def process_single_article(url, save_dir):\n",
    "    image_url = extract_thumbnail_from_html(url)\n",
    "    if image_url:\n",
    "        local_path = download_and_resize_image(image_url, save_dir)\n",
    "    else:\n",
    "        local_path = None\n",
    "    return url, local_path\n",
    "\n",
    "# ==== BƯỚC 7: Tổng hợp toàn bộ pipeline ====\n",
    "def process_articles_from_folder(folder_path):\n",
    "    df = read_all_csv_in_folder(folder_path)\n",
    "    df = preprocess_df(df)\n",
    "\n",
    "    thumbnail_dir = \"/content/drive/MyDrive/Colab Notebooks/NLP/project/thumbnail\"\n",
    "    results = {}\n",
    "\n",
    "    # ==== Đa luồng crawl ảnh ====\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_url = {executor.submit(process_single_article, url, thumbnail_dir): url for url in df['article_url']}\n",
    "        for future in as_completed(future_to_url):\n",
    "            url, thumbnail_path = future.result()\n",
    "            results[url] = thumbnail_path\n",
    "\n",
    "    # ==== Gán lại cột thumbnail ====\n",
    "    df['thumbnail'] = df['article_url'].map(results)\n",
    "\n",
    "    # ==== Ghi ra file CSV ====\n",
    "    df_out = df[['article_url', 'article_title', 'article_description', 'thumbnail', 'label']]\n",
    "    output_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/project/processed_update_articles.csv\"\n",
    "    df_out.to_csv(output_path, index=False)\n",
    "    return df_out\n",
    "\n",
    "process_articles_from_folder(\"/content/drive/MyDrive/Colab Notebooks/NLP/project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6fzJBA3NMlH"
   },
   "source": [
    "**Chạy từ đây**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12175,
     "status": "ok",
     "timestamp": 1752572621417,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "ouiw-i1QsUoC",
    "outputId": "b4d48895-2b5e-40f8-d34d-53c69476fa44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng đầy đủ cả 3 thuộc tính: 86294 / 86762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc lại file đã cập nhật\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/processed_update_articles.csv\")\n",
    "\n",
    "# Điều kiện: cả 3 cột đều không NaN và không rỗng\n",
    "df_full_rows = df[\n",
    "    df['article_title'].notna() & (df['article_title'].str.strip() != \"\") &\n",
    "    df['article_description'].notna() & (df['article_description'].str.strip() != \"\") &\n",
    "    df['thumbnail'].notna() & (df['thumbnail'].str.strip() != \"\")\n",
    "]\n",
    "\n",
    "print(f\"Số dòng đầy đủ cả 3 thuộc tính: {len(df_full_rows)} / {len(df)}\")\n",
    "df_full_rows.to_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/cleaned_articles.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "executionInfo": {
     "elapsed": 2115,
     "status": "ok",
     "timestamp": 1752572625579,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "TFDeW7ZJsvHh",
    "outputId": "2370dfc2-4cfd-4a55-d28a-a96f299e4263"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_full_rows\",\n  \"rows\": 86294,\n  \"fields\": [\n    {\n      \"column\": \"article_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86194,\n        \"samples\": [\n          \"https://www.thesun.ie/tv/14658816/eastenders-natalie-cassidy-dramatic-exit-sonia-fowler/\",\n          \"https://www.irishmirror.ie/news/world-news/gallery/pope-francis-death-thousands-flock-35104869\",\n          \"https://www.rte.ie/news/middle-east/2025/0210/1495776-middle-east-us/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 84036,\n        \"samples\": [\n          \"LISTEN: Shortlist for 2024 RT\\u00c9 Choice Music Prize Irish Song of the Year\",\n          \"Donegal driver killed by falling tree during Storm Eowyn was turning back to avoid danger\",\n          \"WWE star rushed to hospital after risky move goes horribly wrong on live TV leaving fans worried\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 84815,\n        \"samples\": [\n          \"A MOTHER whose 12-year-old son died in the Omagh bomb believes the pain of his loss will never ease, a public inquiry has heard. Shaun McLaughlin was one of three schoolboys who lived in Buncrana in Co Donegal who were killed in the bombing. James Barker, 12, and Oran Doherty, 8, also died. Shaun McLaughlin, 12, was one of the victims of Omagh Bombing in 1998 Shaun McLaughlin with the former president Mary McAleese They had been on a day trip with a group of Spanish students who had been attending a summer programme in the Donegal town. Two Spaniards, a group leader, Rocio Abad Ramos, 23, and one student, Fernando Blasco Baselga, 12, were also killed in the Real IRA attack in August 1998. The outing was to the Ulster American Folk Park just outside Omagh, but the leaders had agreed to let the children finish off the day with a look around the shops in town. A statement written by Shaun\\u2019s mother Patricia was read to the Omagh Bombing Inquiry on Monday by her sister Marjorie McDaid. At the outset of its programme of work, the inquiry is holding four weeks of commemorative hearings to give the families of the 29 victims an opportunity to pay tribute to their lost loved ones. The statement read on Mrs McLaughlin\\u2019s behalf recalled her son as a happy boy who was so excited to be going on the trip to Omagh with his friends. His mother then described the harrowing hours after the blast and the devastating moment the bus arrived back in Buncrana and her son was not on it. \\u201cI sat and watched all the other children get off the bus, but Shaun never got off the bus,\\u201d his mother stated. The statement recalled people lining the streets of towns on the journey to bring Shaun\\u2019s body back to Buncrana days after the bombing. His mother also described his funeral as a \\u201ctotal farce\\u201d, as she expressed frustration that dignitaries appeared to be prioritised ahead of grieving families. \\u201cThere were too many important people there from the political parties, they all even had reserved seats, but there was no reserved seats for the three families who were burying their children,\\u201d she said. Reflecting on the years since the bombing, Mrs McLaughlin described the long-lasting impact on the family, especially Shaun\\u2019s younger siblings Elaine and Christopher. \\u201cIt seems like a lifetime since I held him,\\u201d she added. \\u201cIf somebody had said to me before I lost a child that you will feel exactly the same 26 years later, I wouldn\\u2019t have believed them. I would have thought maybe a couple of years that you would be brokenhearted, but that you will still move on. It\\u2019s going to have to ease. But it just doesn\\u2019t.\\u201d \\u2018RELENTLESS\\u2019 BATTLE FOR ANSWERS Mrs McLaughlin wrote of the \\u201cconstant\\u201d and \\u201crelentless\\u201d battle to find answers as to what happened around the bombing. \\u201cNone of the families deserve what happened that day, but how each of us, in our own way, have had to fight for answers is just awful,\\u201d she stated. \\u201cIt makes me angry at times. I hope that this inquiry will provide the answers as to what happened that day, and hopefully that the cost of Shaun\\u2019s life and all those other lives so tragically lost can provide some hope for us all. \\u201cWe have not gotten over things completely. We never will, but we have learned to live with it. Some days are, of course, harder than others. My firstborn baby will always be in our minds and in our hearts.\\u201d \\u2018HOPE OF PEACE\\u2019 POEM BY THE LATE SON Mrs McLaughlin said her son personified the \\u201chope of peace\\u201d on the island of Ireland following the Good Friday Agreement of April 1998. She said her son had written a poem about the peace accord that he presented to then-president of Ireland Mary McAleese. The poem was read to the inquiry. It reads: \\u201cOrange and green, it doesn\\u2019t matter; \\u201cUnited now, don\\u2019t shatter our dream; \\u201cScatter the seeds of peace over our land; \\u201cSo we can travel hand in hand across the bridge of hope.\\u201d A song that used Shaun\\u2019s poem for part of its lyrics, which was recorded by the Omagh Community Choir, was then played to the inquiry as images of Shaun were displayed. THE IMPACT OF OMAGH BOMBING Inquiry chairman Lord Turnbull paid tribute to the \\u201cstrength\\u201d Mrs McLaughlin had demonstrated in writing her statement. \\u201cIn that statement, Mrs McLaughlin has described, in the clearest way, the lasting impact on a mother of the senseless loss of her firstborn son, a child who was killed before he even reached his teenage years,\\u201d he said. \\u201cMrs McLaughlin\\u2019s statement and the pictures which we\\u2019ve been shown bring to our attention the life of a happy young boy living in a supportive and loving family. \\u201cHer statement also so vividly tells us of the harm and pain inflicted not just on Mrs McLaughlin, but on Shaun\\u2019s brother and sister as well. \\u201cThe experiences which Mrs McLaughlin has described and which other witnesses have spoken of in similar ways will be simply incomprehensible to those with no first-hand knowledge of the Omagh bombing. \\u201cListening to this evidence will make it abundantly clear why these sessions are so important.\\u201d 29 victims tragically lost their lives in the bombing\",\n          \"LAB-grown chicken nuggets may soon be dished up after a scientific breakthrough. Researchers made a 10g piece of poultry from a handful of chicken cells with state-of-the-art tech. Realistic meat is hard to grow without blood vessels, so they were replicated using artificial fibres. A bioreactor machine then pumped nutrients and oxygen around the cells. The result was slightly smaller than a 15-20g standard chicken nugget, but apparently with a similar taste and texture. Previous attempts have mostly been mince \\u2014 combining small pieces. Study author Prof Shoji Takeuchi, of Tokyo University, said: \\u201cOur technology enables the production of structured meat with improved texture and flavour. This could accelerate its commercial viability.\\u201d He did not eat the chicken due to safety protocols but chemical testing indicated \\u201ca mild, savoury flavour and chewiness comparable to real chicken meat\\u201d. The UK Food Standards Agency says lab meat may be available next year. Dr Rodrigo Ledesma-Amaro, of Imperial College London, said: \\u201cWe\\u2019re comfortably on track towards an exciting and appealing new range of products.\\u201d GettyLab-grown chicken nuggets may soon be made available following a scientific breakthrough[/caption]\",\n          \"Colm Hayes and his wife Ann's lives have changed 'completely' since she was diagnosed with stage-four metastatic breast five years ago. Anne is currently undergoing third level chemotherapy and her doting husband Colm has opened up about her diagnosis for the first time. Today's top videos Speaking to The Sun, Colm revealed Ann goes to [\\u2026]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thumbnail\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 81146,\n        \"samples\": [\n          \"/content/drive/MyDrive/Colab Notebooks/NLP/project/thumbnail/e5a8f870efeadb0e9a7b79bd59ba5f61.jpg\",\n          \"/content/drive/MyDrive/Colab Notebooks/NLP/project/thumbnail/310050021724b31b4c5a3cf6e77824b3.jpg\",\n          \"/content/drive/MyDrive/Colab Notebooks/NLP/project/thumbnail/7c46015e9166a4f0422d8af389e16df8.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_full_rows"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3f84e9c7-d431-4ade-8c4a-81441bb42c0a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_url</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_description</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.irishmirror.ie/sport/ufc/conor-mcg...</td>\n",
       "      <td>Why Conor McGregor quickly deletes so many of ...</td>\n",
       "      <td>Conor McGregor has made a bit of a habit of qu...</td>\n",
       "      <td>/content/drive/MyDrive/Colab Notebooks/NLP/pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.thesun.ie/tv/14450756/claudia-wink...</td>\n",
       "      <td>Claudia Winkleman drops big clue over how The ...</td>\n",
       "      <td>CLAUDIA Winkleman has shared a big insight int...</td>\n",
       "      <td>/content/drive/MyDrive/Colab Notebooks/NLP/pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.irishmirror.ie/news/irish-news/jud...</td>\n",
       "      <td>Judge confirms Liam Payne was 'escaping hotel'...</td>\n",
       "      <td>Liam Payne was taken to his room by hotel staf...</td>\n",
       "      <td>/content/drive/MyDrive/Colab Notebooks/NLP/pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.irishmirror.ie/news/irish-news/iri...</td>\n",
       "      <td>Lucky Irish Lotto player scoops €1 million pri...</td>\n",
       "      <td>Along with the €1 million prize winner, six lu...</td>\n",
       "      <td>/content/drive/MyDrive/Colab Notebooks/NLP/pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.irishmirror.ie/news/weird-news/nos...</td>\n",
       "      <td>Nostradamus' terrifying predictions for 2025 -...</td>\n",
       "      <td>The famous astrologer Nostradamus predicted a ...</td>\n",
       "      <td>/content/drive/MyDrive/Colab Notebooks/NLP/pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f84e9c7-d431-4ade-8c4a-81441bb42c0a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3f84e9c7-d431-4ade-8c4a-81441bb42c0a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3f84e9c7-d431-4ade-8c4a-81441bb42c0a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-5264be36-c70a-4e94-9684-c75115bf9642\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5264be36-c70a-4e94-9684-c75115bf9642')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-5264be36-c70a-4e94-9684-c75115bf9642 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                         article_url  \\\n",
       "0  https://www.irishmirror.ie/sport/ufc/conor-mcg...   \n",
       "1  https://www.thesun.ie/tv/14450756/claudia-wink...   \n",
       "2  https://www.irishmirror.ie/news/irish-news/jud...   \n",
       "3  https://www.irishmirror.ie/news/irish-news/iri...   \n",
       "4  https://www.irishmirror.ie/news/weird-news/nos...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Why Conor McGregor quickly deletes so many of ...   \n",
       "1  Claudia Winkleman drops big clue over how The ...   \n",
       "2  Judge confirms Liam Payne was 'escaping hotel'...   \n",
       "3  Lucky Irish Lotto player scoops €1 million pri...   \n",
       "4  Nostradamus' terrifying predictions for 2025 -...   \n",
       "\n",
       "                                 article_description  \\\n",
       "0  Conor McGregor has made a bit of a habit of qu...   \n",
       "1  CLAUDIA Winkleman has shared a big insight int...   \n",
       "2  Liam Payne was taken to his room by hotel staf...   \n",
       "3  Along with the €1 million prize winner, six lu...   \n",
       "4  The famous astrologer Nostradamus predicted a ...   \n",
       "\n",
       "                                           thumbnail  label  \n",
       "0  /content/drive/MyDrive/Colab Notebooks/NLP/pro...      1  \n",
       "1  /content/drive/MyDrive/Colab Notebooks/NLP/pro...      0  \n",
       "2  /content/drive/MyDrive/Colab Notebooks/NLP/pro...      1  \n",
       "3  /content/drive/MyDrive/Colab Notebooks/NLP/pro...      0  \n",
       "4  /content/drive/MyDrive/Colab Notebooks/NLP/pro...      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1752572633181,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "rgPOD8_ucODv",
    "outputId": "8ed670cd-2f3f-4074-f05f-14b95f0ac937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số record có clickbait_level là 4 hoặc 5: 8613\n"
     ]
    }
   ],
   "source": [
    "sum_45 = df_merged[df_merged['clickbait_level'].isin([4, 5])].shape[0]\n",
    "print(\"Tổng số record có clickbait_level là 4 hoặc 5:\", sum_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5375UO-4cRkL"
   },
   "outputs": [],
   "source": [
    "# Lấy toàn bộ dòng có clickbait_level 4 hoặc 5\n",
    "df_45 = df_merged[df_merged['clickbait_level'].isin([4, 5])]\n",
    "\n",
    "# Lấy ngẫu nhiên sum_45 dòng từ level 1\n",
    "df_1_sampled = df_merged[df_merged['clickbait_level'] == 1].sample(n=sum_45, random_state=42)\n",
    "\n",
    "# Kết hợp lại thành new_df\n",
    "new_df = pd.concat([df_45, df_1_sampled], ignore_index=True)\n",
    "\n",
    "# Giữ lại các dòng trong new_df mà article_url có trong df_full_rows\n",
    "merged_df = new_df.merge(df_full_rows, on=\"article_url\", how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1752572654230,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "6viI65Kxczae",
    "outputId": "436ce6b2-d085-4b4b-ac86-48e8d4ca8e1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['article_url',\n",
       " 'article_title_x',\n",
       " 'article_description_x',\n",
       " 'clickbait_level',\n",
       " 'article_title_y',\n",
       " 'article_description_y',\n",
       " 'thumbnail',\n",
       " 'label']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IZH78CfcdPZ"
   },
   "outputs": [],
   "source": [
    "final_df = merged_df[['article_url', 'article_title_y', 'article_description_y', 'thumbnail', 'label']]\n",
    "df_full_rows = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 663,
     "status": "ok",
     "timestamp": 1752572868660,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "WhvbZfEpve7e",
    "outputId": "430063be-6603-4072-ff02-c8f565b3725c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng đầy đủ cả 3 thuộc tính: 17051 / 17051\n",
      "Thống kê số lượng label:\n",
      "Label 0: 8551 mẫu\n",
      "Label 1: 8500 mẫu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-28-3649447135.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_full_rows = df_full_rows[\n"
     ]
    }
   ],
   "source": [
    "#final_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/cleaned_articles.csv\", index=False)\n",
    "\n",
    "# Điều kiện: cả 3 cột đều không NaN và không rỗng\n",
    "df_full_rows = df_full_rows[\n",
    "    df['article_title'].notna() & (df['article_title'].str.strip() != \"\") &\n",
    "    df['article_description'].notna() & (df['article_description'].str.strip() != \"\") &\n",
    "    df['thumbnail'].notna() & (df['thumbnail'].str.strip() != \"\")\n",
    "]\n",
    "\n",
    "print(f\"Số dòng đầy đủ cả 3 thuộc tính: {len(df_full_rows)} / {len(df_full_rows)}\")\n",
    "\n",
    "# Đếm số lượng mỗi giá trị trong cột label\n",
    "label_counts = df_full_rows['label'].value_counts().sort_index()\n",
    "\n",
    "# In kết quả\n",
    "print(\"Thống kê số lượng label:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label {label}: {count} mẫu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4FK4lub_n1D"
   },
   "outputs": [],
   "source": [
    "df_full_rows = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/cleaned_articles.csv\")\n",
    "df_train, df_val, df_test = split_dataset(df_full_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAQX3uLgoVVl"
   },
   "source": [
    "# ***Multimodal Soft-prompt Tuning Few-shot Classification with Ensemble Learning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13049,
     "status": "ok",
     "timestamp": 1753329836929,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "13jrf5C9ye2m",
    "outputId": "0a57b4e4-2ec9-45cb-b65e-c555624432c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.7.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.7.14)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp->torch_geometric) (4.14.1)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "!pip install torch_geometric tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_xzC8xIXI_v"
   },
   "outputs": [],
   "source": [
    "#2\n",
    "# msp_pipeline.py\n",
    "\"\"\"\n",
    "Multimodal Soft Prompt Tuning (Few-shot + Ensemble + Ablation) – 9-step pipeline\n",
    "• Self-contained: chỉ cần DataFrame `df_full_rows` (các cột: article_title,\n",
    "  article_description, thumbnail, label ∈ {0,1}) + GPU/Torch.\n",
    "\"\"\"\n",
    "\n",
    "# ===== 0. Imports =====\n",
    "import os, random, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, precision_recall_curve, auc)\n",
    "from transformers import (RobertaTokenizer, RobertaModel,\n",
    "                          RobertaForMaskedLM, CLIPModel)\n",
    "from torch_geometric.nn import GATConv\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "import gc\n",
    "\n",
    "\n",
    "# ===== 1. Data Preparation =====\n",
    "def prepare_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_full_rows = df[\n",
    "                      df['article_title'].notna() & (df['article_title'].str.strip() != \"\") &\n",
    "                      df['article_description'].notna() & (df['article_description'].str.strip() != \"\") &\n",
    "                      df['thumbnail'].notna() & (df['thumbnail'].str.strip() != \"\")\n",
    "                    ].copy()\n",
    "    return df_full_rows\n",
    "\n",
    "def split_dataset(df: pd.DataFrame, seed=42):\n",
    "    df_trainval, df_test = train_test_split(df, test_size=0.1, stratify=df.label, random_state=seed)\n",
    "    df_train, df_val = train_test_split(df_trainval, test_size=2/9, stratify=df_trainval.label, random_state=seed)\n",
    "    return df_train.reset_index(drop=True), df_val.reset_index(drop=True), df_test.reset_index(drop=True)\n",
    "\n",
    "# ===== 2. Few-shot Sampler =====\n",
    "def sample_k_shot(df: pd.DataFrame, k: int, seed: int) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return (\n",
    "        df.groupby(\"label\", group_keys=False)\n",
    "          .apply(lambda x: x.sample(n=k, random_state=rng.integers(1e6)).assign(label=x.name),\n",
    "                 include_groups=False)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# ===== 3. Dataset & Dataloaders =====\n",
    "class ClickbaitDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, img_tf):\n",
    "        self.df, self.tok, self.tf = df.reset_index(drop=True), tokenizer, img_tf\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.df.loc[idx]\n",
    "        toks = self.tok(r.article_title, r.article_description,\n",
    "                        padding='max_length', truncation=True,\n",
    "                        max_length=128, return_tensors='pt')\n",
    "        try:\n",
    "            img = Image.open(r.thumbnail).convert('RGB')\n",
    "        except:                           # nếu lỗi ảnh ⇒ ảnh đen\n",
    "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        return {\"input_ids\": toks.input_ids.squeeze(0),\n",
    "                \"attention_mask\": toks.attention_mask.squeeze(0),\n",
    "                \"image\": self.tf(img),\n",
    "                \"label\": torch.tensor(r.label, dtype=torch.float),\n",
    "                \"title\": r.article_title}\n",
    "\n",
    "def create_dataloader(df, tokenizer, transform, bs, shuffle=True, drop_last=True):\n",
    "    dataset = ClickbaitDataset(df, tokenizer, transform)\n",
    "    return DataLoader(dataset, batch_size=bs, shuffle=shuffle, drop_last=drop_last, num_workers=8, pin_memory=True)\n",
    "\n",
    "# ===== 4. Base Blocks =====\n",
    "# 4-a) Syntactic encoder (GAT over dependency graph)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "POS2IDX = {t: i for i, t in enumerate(nlp.get_pipe(\"tagger\").labels)}\n",
    "\n",
    "class SyntacticEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(POS2IDX), 128)\n",
    "        self.gat = GATConv(128, 256)\n",
    "        self.elu = nn.ELU()\n",
    "        self.project = nn.Linear(256, 768)\n",
    "\n",
    "    def forward(self, titles):\n",
    "        device = next(self.parameters()).device\n",
    "        feats = []\n",
    "        for text in titles:\n",
    "            doc = nlp(text)\n",
    "            edge_index = torch.tensor([(t.i, c.i) for t in doc for c in t.children] or [(0, 0)],\n",
    "                                      dtype=torch.long).t().to(device)\n",
    "            pos_ids = torch.tensor([POS2IDX.get(t.tag_, 0) for t in doc], dtype=torch.long).to(device)\n",
    "            x = self.embedding(pos_ids)\n",
    "            x = self.gat(x, edge_index)\n",
    "            x = self.elu(x)\n",
    "            feats.append(self.project(x.mean(0)))\n",
    "        return torch.stack(feats)\n",
    "\n",
    "# 4-b) Soft prompt helper\n",
    "class SoftPrompt(nn.Module):\n",
    "    def __init__(self, n, d): super().__init__(); self.p = nn.Parameter(torch.randn(n, d))\n",
    "    def forward(self, b): return self.p.unsqueeze(0).expand(b, -1, -1)\n",
    "\n",
    "# 4-c) Prompted text encoder (Roberta-MLM)\n",
    "class PromptedText(nn.Module):\n",
    "    def __init__(self, prompt=True):\n",
    "        super().__init__()\n",
    "        self.base = RobertaForMaskedLM.from_pretrained('roberta-large') if prompt \\\n",
    "                    else RobertaModel.from_pretrained('roberta-large')\n",
    "        self.p_len = 5 if prompt else 0\n",
    "        self.prompt = SoftPrompt(self.p_len, self.base.config.hidden_size) if prompt else None\n",
    "    def forward(self, ids, mask):\n",
    "        if self.prompt is None: return self.base(ids, attention_mask=mask).last_hidden_state.mean(1)\n",
    "        embeds = self.base.roberta.embeddings.word_embeddings(ids)\n",
    "        p = self.prompt(embeds.size(0))\n",
    "        embeds = torch.cat([p, embeds], 1)\n",
    "        m = torch.cat([torch.ones(ids.size(0), self.p_len, device=ids.device), mask], 1)\n",
    "        out = self.base.roberta(inputs_embeds=embeds, attention_mask=m)\n",
    "        return (out.last_hidden_state * m.unsqueeze(-1)).sum(1) / (m.sum(1, keepdim=True) + 1e-9)\n",
    "\n",
    "# 4-d) Prompted image encoder\n",
    "class PromptedImage(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        dim = self.base.vision_model.config.hidden_size\n",
    "        self.prompt = SoftPrompt(5, dim)\n",
    "        self.conv = nn.Sequential(nn.Conv1d(dim, 256, 1), nn.ReLU(),\n",
    "                                  nn.AdaptiveAvgPool1d(1))\n",
    "        self.out = nn.Linear(256, 768)\n",
    "    def forward(self, img):\n",
    "        hid = self.base.vision_model(pixel_values=img).last_hidden_state     # [b, seq, d]\n",
    "        p = self.prompt(hid.size(0)).mean(1).unsqueeze(1)\n",
    "        h = torch.cat([p, hid], 1).transpose(1, 2)                           # [b, d, seq+1]\n",
    "        return self.out(self.conv(h).squeeze(-1))\n",
    "\n",
    "# 4-e) Loss helpers\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(s, a=1.0, g=2.0): super().__init__(); s.a, s.g = a, g\n",
    "    def forward(s, logit, y):\n",
    "        bce = nn.functional.binary_cross_entropy_with_logits(logit, y, reduction='none')\n",
    "        pt = torch.exp(-bce); return (s.a * (1 - pt)**s.g * bce).mean()\n",
    "\n",
    "def get_balanced_bce(df, device):\n",
    "    pos, neg = (df.label == 1).sum(), (df.label == 0).sum()\n",
    "    return nn.BCEWithLogitsLoss(pos_weight=torch.tensor([neg/pos]).to(device))\n",
    "\n",
    "# ===== 5. Build variant model factory =====\n",
    "def build_model(fusion='concat', prompt=True, loss='focal', df_train=None, device='cuda'):\n",
    "    class MSP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.txt = PromptedText(prompt)\n",
    "            self.img = PromptedImage()\n",
    "            self.syn = SyntacticEncoder()\n",
    "            self.tp, self.ip, self.sp = nn.Linear(self.txt.base.config.hidden_size, 256),\\\n",
    "                                        nn.Linear(768, 256), nn.Linear(768, 256)\n",
    "            if fusion == 'concat':\n",
    "                self.fuse = nn.Sequential(nn.Linear(256*3, 512), nn.ReLU(),\n",
    "                                          nn.Dropout(0.3), nn.Linear(512, 1))\n",
    "            else:                       # gated\n",
    "                self.gate = nn.Sequential(nn.Linear(256 * 3, 256 * 3), nn.Sigmoid())\n",
    "                self.fuse = nn.Sequential(nn.Linear(256 * 3, 128), nn.ReLU(),\n",
    "                                          nn.Dropout(0.3), nn.Linear(128, 1))\n",
    "        def forward(self, ids, mask, img, titles):\n",
    "            t = self.tp(self.txt(ids, mask))\n",
    "            i = self.ip(self.img(img))\n",
    "            s = self.sp(self.syn(titles))\n",
    "            cat = torch.cat([t, i, s], 1)\n",
    "            if fusion == 'concat': out = self.fuse(cat)\n",
    "            else: out = self.fuse(self.gate(cat) * cat)\n",
    "            return out.squeeze(-1)\n",
    "    if loss == 'focal':\n",
    "        loss_fn = FocalLoss()\n",
    "    elif loss == 'bce':\n",
    "        loss_fn = get_balanced_bce(df_train, device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported loss: {loss}\")\n",
    "\n",
    "    return MSP(), loss_fn\n",
    "\n",
    "# ===== 6. Variant Train hyper-params =====\n",
    "VARIANTS = [\n",
    "    {'bs': 24, 'lr': 5e-4, 'fusion': 'gated',  'loss': 'focal'},\n",
    "    {'bs': 32, 'lr': 5e-4, 'fusion': 'concat', 'loss': 'focal'},\n",
    "    {'bs': 32, 'lr': 2e-4, 'fusion': 'gated',  'loss': 'focal'},\n",
    "    {'bs': 32, 'lr': 5e-4, 'fusion': 'gated',  'loss': 'bce'},\n",
    "    {'bs': 32, 'lr': 2e-4, 'fusion': 'gated',  'loss': 'focal'},\n",
    "]\n",
    "def train_variant(i, df_train, df_val, tok, tfm, dev, save_dir=\"/content/drive/MyDrive/Colab Notebooks/NLP/project/\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    config = VARIANTS[i]\n",
    "    print(f\"Training variant {i}: {config} | \")\n",
    "\n",
    "    tr_loader = create_dataloader(df_train, tok, tfm, config['bs'], shuffle=True, drop_last=True)\n",
    "    va_loader = create_dataloader(df_val, tok, tfm, config['bs'], shuffle=False, drop_last=False)\n",
    "\n",
    "    model, loss_fn = build_model(fusion=config['fusion'], prompt=True, loss=config['loss'],\n",
    "                                 df_train=df_train, device=dev)\n",
    "    model.to(dev)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "\n",
    "    for epoch in range(3):\n",
    "        model.train()\n",
    "        loop = tqdm(tr_loader, desc=f\"Epoch {epoch+1}/{3}\", leave=True)\n",
    "        for b in loop:\n",
    "            opt.zero_grad()\n",
    "            l = model(b['input_ids'].to(dev),\n",
    "                      b['attention_mask'].to(dev),\n",
    "                      b['image'].to(dev),\n",
    "                      b['title']).to(dev)\n",
    "            loss = loss_fn(l, b['label'].to(dev))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    for b in tqdm(va_loader, desc=f\"Validating...\", leave=True):\n",
    "        with torch.no_grad():\n",
    "            p = model(b['input_ids'].to(dev),\n",
    "                      b['attention_mask'].to(dev),\n",
    "                      b['image'].to(dev),\n",
    "                      b['title']).sigmoid().cpu()\n",
    "        preds.append(p)\n",
    "        labels.append(b['label'])\n",
    "\n",
    "    pred = (torch.cat(preds) > 0.5).int()\n",
    "    true = torch.cat(labels)\n",
    "    acc = accuracy_score(true, pred)\n",
    "    f1 = f1_score(true, pred)\n",
    "    print(f\" - val_acc={acc:.4f}, f1={f1:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f\"variant_{i}.pt\"))\n",
    "    return acc, f1\n",
    "\n",
    "def load_models(idxs: list, df_train, device='cuda', save_dir=\"/content/drive/MyDrive/Colab Notebooks/NLP/project/\"):\n",
    "    models = []\n",
    "    for i in idxs:\n",
    "        config = VARIANTS[i]\n",
    "        model, _ = build_model(fusion=config['fusion'], prompt=True, loss=config['loss'],\n",
    "                               df_train=df_train, device=device)\n",
    "        model.load_state_dict(torch.load(os.path.join(save_dir, f\"variant_{i}.pt\"), map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "# ===== 7. Full Test - Ensemble =====\n",
    "def full_eval_run(df_test, models, weights, tok, tfm, dev, bs):\n",
    "    print(f\"Running full-set ensemble evaluation...\")\n",
    "    te_loader = create_dataloader(df_test, tok, tfm, bs=bs, shuffle=False, drop_last=False)\n",
    "    probs = []\n",
    "\n",
    "    for i, m in enumerate(models):\n",
    "        m.eval()\n",
    "        pred = []\n",
    "        for b in tqdm(te_loader, desc=f\"Model {i}/{len(models)-1}\", leave=False):\n",
    "            with torch.no_grad():\n",
    "                p = m(b['input_ids'].to(dev),\n",
    "                      b['attention_mask'].to(dev),\n",
    "                      b['image'].to(dev),\n",
    "                      b['title']).sigmoid().cpu()\n",
    "            pred.append(p)\n",
    "        probs.append(torch.cat(pred))\n",
    "\n",
    "    # Hard voting\n",
    "    bin_preds = [(p > 0.5).int() for p in probs]\n",
    "    votes = sum(p * w for p, w in zip(bin_preds, weights))\n",
    "    pred = (votes > 0.5).int()\n",
    "\n",
    "    # Ground-truth\n",
    "    y = torch.cat([b['label'] for b in te_loader])\n",
    "\n",
    "    acc = accuracy_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    rc = recall_score(y, pred)\n",
    "\n",
    "    # Soft-voting for PR AUC\n",
    "    soft_final = sum(p * w for p, w in zip(probs, weights))\n",
    "    pr, rc_curve, _ = precision_recall_curve(y, soft_final)\n",
    "    pr_auc = auc(rc_curve, pr)\n",
    "\n",
    "    print(f\"  Full-set → acc={acc:.4f}, f1={f1:.4f}, recall={rc:.4f}, PR-AUC={pr_auc:.4f}\")\n",
    "    return dict(acc=acc, f1=f1, recall=rc, pr_auc=pr_auc)\n",
    "\n",
    "# ===== 8. Few-shot run + logging =====\n",
    "def fewshot_run(fewshot_df, models, weights, k, tok, tfm, dev, bs):\n",
    "    print(f\"Running few-shot experiment with k={k}\")\n",
    "    te_loader = create_dataloader(fewshot_df, tok, tfm, bs=bs, shuffle=False, drop_last=False)\n",
    "    probs = []\n",
    "\n",
    "    for i, m in enumerate(models):\n",
    "        m.eval()\n",
    "        pred = []\n",
    "        for b in tqdm(te_loader, desc=f\"Model {i}/{len(models)-1}\", leave=True):\n",
    "            with torch.no_grad():\n",
    "                p = m(b['input_ids'].to(dev),\n",
    "                      b['attention_mask'].to(dev),\n",
    "                      b['image'].to(dev),\n",
    "                      b['title']).sigmoid().cpu()\n",
    "            pred.append(p)\n",
    "        probs.append(torch.cat(pred))\n",
    "\n",
    "    bin_preds = [(p > 0.5).int() for p in probs]\n",
    "    votes = sum(p * w for p, w in zip(bin_preds, weights))\n",
    "    final = (votes > 0.5).int()\n",
    "    pred = (final > 0.5).int()\n",
    "    y = torch.cat([b['label'] for b in te_loader])\n",
    "\n",
    "    acc = accuracy_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    rc = recall_score(y, pred)\n",
    "    soft_final = sum(p * w for p, w in zip(probs, weights))\n",
    "    pr, rc_curve, _ = precision_recall_curve(y, soft_final)\n",
    "    pr_auc = auc(rc_curve, pr)\n",
    "\n",
    "    print(f\"  k={k} → acc={acc:.4f}, f1={f1:.4f}\")\n",
    "    return dict(k=k, acc=acc, f1=f1, recall=rc, pr_auc=pr_auc)\n",
    "\n",
    "\n",
    "\n",
    "# ===== 10. Visualization helpers (bước 9) =====\n",
    "def plot_results(results_df):\n",
    "    # ---- Biểu đồ cột nhóm: acc và f1 vs. k-shot ----\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "    # Chuyển đổi dữ liệu sang dạng \"long\" cho dễ vẽ grouped bar\n",
    "    df_melt = results_df.melt(id_vars='k', value_vars=['acc', 'f1'],\n",
    "                              var_name='Metric', value_name='Score')\n",
    "\n",
    "    sns.barplot(x='k', y='Score', hue='Metric', data=df_melt)\n",
    "    plt.title(\"Accuracy & F1 vs. k-shot\")\n",
    "    plt.xlabel(\"k-shot (samples per class)\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend(title=\"Metric\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DhjlYiku7Aq0"
   },
   "outputs": [],
   "source": [
    "#3\n",
    "df_train = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/df_train.pkl\")\n",
    "df_val = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/df_val.pkl\")\n",
    "df_test = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/df_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Variants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "fdb9cb46541948bdb23305fbf6894586",
      "fb47ccf6d173400b8bb29e8e10b0ca25",
      "3a5df8e917e54e46bf0ea4506e089509",
      "9c15a74798e5400488e8e29b9a91bd75",
      "e89d9ab593334ca8923c8c8d89af1828",
      "5a53a115ddfc4dd7bd8598d078a39d12",
      "9a8aaefb2a1c49818c295250349b9861",
      "71eb596539be43f9a8a3d98c1eb44454",
      "f9c0ccc317ff4ab9944056b2d4dacbe5",
      "54028dade2ec4239b74078dc435328c9",
      "85f2ee5b4d7148d592c171e40a552afe",
      "9f47e5e47ffe4dce9699a123de1a7c68",
      "8fa5a125555f455fa948a58c6a8f6973",
      "14b949f12d0a4e7b8fea2b2646582bb1",
      "cdfe7fb66f3843ea9024b3231611fee3",
      "f42359b5f7b9425a9b1bf5a9cf58078f",
      "0c9f8d493a0745dea19d0466ae102afe",
      "3e608194dc7f4f748c75d28956df1172",
      "8aaec58b36d34dff9995b594eacc026b",
      "1c38f297a00f4ea880549cd6507631d3",
      "7dee146f64a641998084dca627af1b04",
      "8fce034853f24f238f76116be28b46cc",
      "cf12f6ee644b480591fc462a2281bc59",
      "2f937d2a665846ea8785d7050fdf5de0",
      "33df6b79623b44ce93595e2bd87211bd",
      "59953e2d56f34d0fa087540787e14203",
      "664dd60b94ee40d0a5b7ca4171abdf5f",
      "105c62decd7943a78c8feb95a9bdd497",
      "c4b6cb9babdd441a9fe1e4e68efc44f6",
      "223d702e741c4e4296fecdeb705687f8",
      "b89662e21cef4e929d75008c75f1841e",
      "c72fe2f084fb4c7ba1e4bb6e2ef70bd5",
      "0b7eba9b0c1f4981b47261d27dacd19c",
      "9416b2a869f64ad9844397b61f73b707",
      "cbe6ebfba45543b1a97f0dad7137ad1c",
      "618ff56aece14051a252f297838ae459",
      "3c3fb90da4724bfab0a33083b39c6396",
      "543475f3a94c4737b81eed00156b698b",
      "5f63316006404709bba20f2b79013768",
      "443add0ab33848d2bd316bdebe7e9bb5",
      "ac58c2ab09814202bd94dd3ad03642d4",
      "d85464d80f6244399044fec41c7a7540",
      "12c5d4841d6c410097f102e99ab6bc46",
      "8d427fe22da84eaa9ce1130eec99e936"
     ]
    },
    "executionInfo": {
     "elapsed": 1910,
     "status": "ok",
     "timestamp": 1753330829398,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "xs2NDHqb_v5a",
    "outputId": "ffaf41e0-8f20-46e7-b782-ae86ce1b533f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb9cb46541948bdb23305fbf6894586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f47e5e47ffe4dce9699a123de1a7c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf12f6ee644b480591fc462a2281bc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9416b2a869f64ad9844397b61f73b707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "img_tf = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "67229614724a48cf8104f880192a29d8",
      "b4158fcf694c47259da65620227cc76e",
      "7ec1ba64d9514077b2deb533d8a0c28a",
      "18260976b16e42928620d96cf142b880",
      "cd2f98d740f94340bd0a301b13c29e1f",
      "ec2076de66dd4108ad092318776eb225",
      "0d5d730456cd419381fb380742ade9dd",
      "7bd657ef12674e3e88209b80474d2b31",
      "06479762aef24b22a90e3bb06505dc6f",
      "b5e0782f47724023b53262fb69ebfcf8",
      "d78f5faa44204ebcba34fcfe5ba6055e",
      "351af7f754c94a2e9418a1c38543ae69",
      "1ab09d8ec728449da7bbb371debc9f1c",
      "8b4f0af0f580401895ee0825eeeb1ff9",
      "fca9611b63734829b7e342b9bd06da60",
      "6dc8791f70f3492390f6639c573b2212",
      "ef85086c643445789c190322cf1afced",
      "ccbeb5bcbd0d403e8d819c2cefd07e07",
      "b33560e3e8f6438fb92be1e8de93b1bf",
      "036f802a7a7048e6b6d0721123040be6",
      "92f995aafd364b2caeafaf5780839d54",
      "873c926708ef45df96d41c8d72c1a5b2",
      "ea747a0a5f954f3ca2924471fc7e735a",
      "19aa356e40b0471fade10bec2d5ea618",
      "ad1ed522edb24fe582e413d9d312fb97",
      "9ce4a49efc0b448d87012fdca5da50e5",
      "d179490b99d3448ab2b7241addc7e10a",
      "d268da03d413444ba12b1e61f0f5abc3",
      "0437533cb4a444559772d8f37d21a45b",
      "655fc9aed5804da7a65ec6abb4054cd9",
      "6a726ddcf4c6412b90a79bd56dda05d0",
      "32c337438b104b80a7daa2b7623ed37c",
      "1651970a5ce5412cac9a4025de7e3149",
      "e04f247de82b42a2bc246d8e641ad7a7",
      "e193b9e59c0c4ba0aa3aa49c96578f67",
      "48d2f8112c864d59ae9cd015b959f143",
      "a8107aa683214922ad62bbf106118004",
      "1963da5716004e1782365040f23ac2a0",
      "2491c1b0598c4500b4f0820856110c48",
      "99c45bbc18ba46a996acead3fe63fb82",
      "8c3459e7e5d245498a90c71e4171709f",
      "ccc1dc1d701c48618b958eabf44f0144",
      "2bf0e51b759643aeb5b4c8936941ae90",
      "54c7af68b7944a5dae397792b0667255"
     ]
    },
    "executionInfo": {
     "elapsed": 2220712,
     "status": "ok",
     "timestamp": 1752828537719,
     "user": {
      "displayName": "Thanh Sang Lê",
      "userId": "09771502319100460389"
     },
     "user_tz": -420
    },
    "id": "RT3q_y7buCCR",
    "outputId": "da9c2b13-b4a1-4adc-dd5b-d5d42ad6e3ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training variant 0: {'bs': 24, 'lr': 0.0005, 'fusion': 'gated', 'loss': 'focal'} | \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67229614724a48cf8104f880192a29d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351af7f754c94a2e9418a1c38543ae69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea747a0a5f954f3ca2924471fc7e735a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 1/3:   0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04f247de82b42a2bc246d8e641ad7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 497/497 [13:00<00:00,  1.57s/it, loss=0.112]\n",
      "Epoch 2/3: 100%|██████████| 497/497 [09:22<00:00,  1.13s/it, loss=0.079]\n",
      "Epoch 3/3: 100%|██████████| 497/497 [09:14<00:00,  1.12s/it, loss=0.144]\n",
      "Validating...: 100%|██████████| 143/143 [04:59<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - val_acc=0.7997, f1=0.8019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7997067448680352, 0.8018566869741804)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "train_variant(0, df_train, df_val, tokenizer, img_tf, device)\n",
    "#need re-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "81d3f15eb548404f9c8113aa7936b7d6",
      "b90216afeda24527bf6ac385f50e23f0",
      "1d18a96b6f4241488671771f3c3b7ae7",
      "d92a6e15a746450187fbdae3eddb8209",
      "292290177d2549799e3df5420005ff62",
      "4a8340ca63624eb7bf85fd681095efa1",
      "5b1fef3291264f139860879e497fbdc6",
      "b562f6f4d8634b90b3aa846733ac4da5",
      "5900c74821384dd3a8e99ce35dbad08c",
      "332815321e904c64b0e2ecfb35b9abde",
      "823d168fd28d47b5a897bb1d75766ae2",
      "bc408cb5871848be819a2745a9e779dc",
      "c514eab65b7442b38334bc283829213c",
      "40c401bd203547cdae11802ad428d46c",
      "4b13d43792614da59cc993d2cf3b45e5",
      "ac870d328a3f409fb26fe13d60513a55",
      "2bbadcc0a9444fd6846c04f246c1a046",
      "2a4760f64d064562b6b1edea25fcc634",
      "ed319091cbed4b3681de7935e269a9b3",
      "036128c6a0c34c6c80a61279c1433df2",
      "ed5f7d8742c04875a9186fb9ccfc7a7a",
      "f9f99a70ab80444db2cbc8e9ab1d46c9",
      "c7e96dc415224e7592d2719ab4d5aaa1",
      "ef27b2a971224b77b5fd30bb26e0a707",
      "49d8763c230d401b9f7031127fccffd9",
      "682a4d5e2c1c499fb5bc85ba40a2c10a",
      "bd1f8341deb94cfd9419fa87d52d20a1",
      "7aeade2e438c466fb6fc2f709adf12b9",
      "3101eb41ce594442b741447282713108",
      "0a2ac4fe172142489b767c748e23bd55",
      "e8cce1a28b384235980a2027769ba1e1",
      "187cd385ade04ffeb8381ae2ccca5188",
      "fc2788c11c9e48cbb662da0805bf8d9d",
      "309bfe099d434b289f7fdf71fd4b8241",
      "e787b5fcdbf64569b2d9fcfd756dcd71",
      "cea4ac865f494d1f984fb86feb42aeb2",
      "cdc60cbf7ca84a348163a3f9c763ec96",
      "9983da3670bc4be6bc50046769c434b2",
      "4a91555fbe87411a89777cb9025f5904",
      "f8448b4eafdc400aad32f4cb54f76077",
      "c882d8702819489e98f85b8a8b412b8b",
      "fdc77898a5144b7a9292516ef3755bb4",
      "a3c0e1aab1f5441ca5150deecc9b0d32",
      "f71e1cead5204461a6b90c5f76e5eeca"
     ]
    },
    "executionInfo": {
     "elapsed": 2281659,
     "status": "ok",
     "timestamp": 1752830925252,
     "user": {
      "displayName": "Thanh Sang Lê",
      "userId": "09771502319100460389"
     },
     "user_tz": -420
    },
    "id": "G45afnAbuClG",
    "outputId": "6980caf4-639d-4fdf-859a-4db417244c04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training variant 1: {'bs': 32, 'lr': 0.0005, 'fusion': 'concat', 'loss': 'focal'} | \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d3f15eb548404f9c8113aa7936b7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc408cb5871848be819a2745a9e779dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e96dc415224e7592d2719ab4d5aaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309bfe099d434b289f7fdf71fd4b8241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3:   0%|          | 0/372 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1/3:   0%|          | 0/372 [04:46<?, ?it/s, loss=0.185]\u001b[A\n",
      "Epoch 1/3:   0%|          | 1/372 [04:46<29:33:38, 286.84s/it, loss=0.185]\u001b[A\n",
      "Epoch 1/3:   0%|          | 1/372 [04:48<29:33:38, 286.84s/it, loss=0.294]\u001b[A\n",
      "Epoch 1/3:   1%|          | 2/372 [04:48<12:13:45, 118.99s/it, loss=0.294]\u001b[A\n",
      "Epoch 1/3:   1%|          | 2/372 [04:49<12:13:45, 118.99s/it, loss=0.174]\u001b[A\n",
      "Epoch 1/3:   1%|          | 3/372 [04:49<6:41:54, 65.35s/it, loss=0.174]  \u001b[A\n",
      "Epoch 1/3:   1%|          | 3/372 [04:51<6:41:54, 65.35s/it, loss=0.178]\u001b[A\n",
      "Epoch 1/3:   1%|          | 4/372 [04:51<4:06:17, 40.16s/it, loss=0.178]\u001b[A\n",
      "Epoch 1/3:   1%|          | 4/372 [04:52<4:06:17, 40.16s/it, loss=0.193]\u001b[A\n",
      "Epoch 1/3:   1%|▏         | 5/372 [04:52<2:40:22, 26.22s/it, loss=0.193]\u001b[A\n",
      "Epoch 1/3:   1%|▏         | 5/372 [04:54<2:40:22, 26.22s/it, loss=0.321]\u001b[A\n",
      "Epoch 1/3:   2%|▏         | 6/372 [04:54<1:48:42, 17.82s/it, loss=0.321]\u001b[A\n",
      "Epoch 1/3:   2%|▏         | 6/372 [04:55<1:48:42, 17.82s/it, loss=0.17] \u001b[A\n",
      "Epoch 1/3:   2%|▏         | 7/372 [04:55<1:16:04, 12.50s/it, loss=0.17]\u001b[A\n",
      "Epoch 1/3:   2%|▏         | 7/372 [04:57<1:16:04, 12.50s/it, loss=0.173]\u001b[A\n",
      "Epoch 1/3:   2%|▏         | 8/372 [04:57<54:41,  9.02s/it, loss=0.173]  \u001b[A\n",
      "Epoch 1/3:   2%|▏         | 8/372 [04:59<54:41,  9.02s/it, loss=0.173]\u001b[A\n",
      "Epoch 1/3:   2%|▏         | 9/372 [04:59<40:20,  6.67s/it, loss=0.173]\u001b[A\n",
      "Epoch 1/3:   2%|▏         | 9/372 [05:01<40:20,  6.67s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:   3%|▎         | 10/372 [05:01<33:10,  5.50s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:   3%|▎         | 10/372 [05:03<33:10,  5.50s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:   3%|▎         | 11/372 [05:03<25:45,  4.28s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:   3%|▎         | 11/372 [05:04<25:45,  4.28s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:   3%|▎         | 12/372 [05:04<20:39,  3.44s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:   3%|▎         | 12/372 [05:06<20:39,  3.44s/it, loss=0.164]\u001b[A\n",
      "Epoch 1/3:   3%|▎         | 13/372 [05:06<17:08,  2.87s/it, loss=0.164]\u001b[A\n",
      "Epoch 1/3:   3%|▎         | 13/372 [05:08<17:08,  2.87s/it, loss=0.167]\u001b[A\n",
      "Epoch 1/3:   4%|▍         | 14/372 [05:08<14:42,  2.46s/it, loss=0.167]\u001b[A\n",
      "Epoch 1/3:   4%|▍         | 14/372 [05:09<14:42,  2.46s/it, loss=0.207]\u001b[A\n",
      "Epoch 1/3:   4%|▍         | 15/372 [05:09<12:59,  2.18s/it, loss=0.207]\u001b[A\n",
      "Epoch 1/3:   4%|▍         | 15/372 [05:11<12:59,  2.18s/it, loss=0.118]\u001b[A\n",
      "Epoch 1/3:   4%|▍         | 16/372 [05:11<11:48,  1.99s/it, loss=0.118]\u001b[A\n",
      "Epoch 1/3:   4%|▍         | 16/372 [05:12<11:48,  1.99s/it, loss=0.21] \u001b[A\n",
      "Epoch 1/3:   5%|▍         | 17/372 [05:12<10:57,  1.85s/it, loss=0.21]\u001b[A\n",
      "Epoch 1/3:   5%|▍         | 17/372 [05:14<10:57,  1.85s/it, loss=0.131]\u001b[A\n",
      "Epoch 1/3:   5%|▍         | 18/372 [05:14<11:23,  1.93s/it, loss=0.131]\u001b[A\n",
      "Epoch 1/3:   5%|▍         | 18/372 [05:16<11:23,  1.93s/it, loss=0.156]\u001b[A\n",
      "Epoch 1/3:   5%|▌         | 19/372 [05:16<10:38,  1.81s/it, loss=0.156]\u001b[A\n",
      "Epoch 1/3:   5%|▌         | 19/372 [05:17<10:38,  1.81s/it, loss=0.259]\u001b[A\n",
      "Epoch 1/3:   5%|▌         | 20/372 [05:17<10:15,  1.75s/it, loss=0.259]\u001b[A\n",
      "Epoch 1/3:   5%|▌         | 20/372 [05:19<10:15,  1.75s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:   6%|▌         | 21/372 [05:19<09:52,  1.69s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:   6%|▌         | 21/372 [05:20<09:52,  1.69s/it, loss=0.159]\u001b[A\n",
      "Epoch 1/3:   6%|▌         | 22/372 [05:20<09:34,  1.64s/it, loss=0.159]\u001b[A\n",
      "Epoch 1/3:   6%|▌         | 22/372 [05:22<09:34,  1.64s/it, loss=0.174]\u001b[A\n",
      "Epoch 1/3:   6%|▌         | 23/372 [05:22<09:20,  1.61s/it, loss=0.174]\u001b[A\n",
      "Epoch 1/3:   6%|▌         | 23/372 [05:24<09:20,  1.61s/it, loss=0.169]\u001b[A\n",
      "Epoch 1/3:   6%|▋         | 24/372 [05:24<09:11,  1.59s/it, loss=0.169]\u001b[A\n",
      "Epoch 1/3:   6%|▋         | 24/372 [05:25<09:11,  1.59s/it, loss=0.193]\u001b[A\n",
      "Epoch 1/3:   7%|▋         | 25/372 [05:25<09:04,  1.57s/it, loss=0.193]\u001b[A\n",
      "Epoch 1/3:   7%|▋         | 25/372 [05:27<09:04,  1.57s/it, loss=0.154]\u001b[A\n",
      "Epoch 1/3:   7%|▋         | 26/372 [05:27<09:00,  1.56s/it, loss=0.154]\u001b[A\n",
      "Epoch 1/3:   7%|▋         | 26/372 [05:28<09:00,  1.56s/it, loss=0.172]\u001b[A\n",
      "Epoch 1/3:   7%|▋         | 27/372 [05:28<08:56,  1.55s/it, loss=0.172]\u001b[A\n",
      "Epoch 1/3:   7%|▋         | 27/372 [05:30<08:56,  1.55s/it, loss=0.157]\u001b[A\n",
      "Epoch 1/3:   8%|▊         | 28/372 [05:30<08:51,  1.54s/it, loss=0.157]\u001b[A\n",
      "Epoch 1/3:   8%|▊         | 28/372 [05:31<08:51,  1.54s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:   8%|▊         | 29/372 [05:31<08:48,  1.54s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:   8%|▊         | 29/372 [05:33<08:48,  1.54s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:   8%|▊         | 30/372 [05:33<08:47,  1.54s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:   8%|▊         | 30/372 [05:34<08:47,  1.54s/it, loss=0.156]\u001b[A\n",
      "Epoch 1/3:   8%|▊         | 31/372 [05:34<08:46,  1.54s/it, loss=0.156]\u001b[A\n",
      "Epoch 1/3:   8%|▊         | 31/372 [05:36<08:46,  1.54s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:   9%|▊         | 32/372 [05:36<08:45,  1.54s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:   9%|▊         | 32/372 [05:38<08:45,  1.54s/it, loss=0.186]\u001b[A\n",
      "Epoch 1/3:   9%|▉         | 33/372 [05:38<09:45,  1.73s/it, loss=0.186]\u001b[A\n",
      "Epoch 1/3:   9%|▉         | 33/372 [05:40<09:45,  1.73s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:   9%|▉         | 34/372 [05:40<09:29,  1.69s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:   9%|▉         | 34/372 [05:41<09:29,  1.69s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:   9%|▉         | 35/372 [05:41<09:11,  1.64s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:   9%|▉         | 35/372 [05:47<09:11,  1.64s/it, loss=0.15] \u001b[A\n",
      "Epoch 1/3:  10%|▉         | 36/372 [05:47<16:14,  2.90s/it, loss=0.15]\u001b[A\n",
      "Epoch 1/3:  10%|▉         | 36/372 [05:48<16:14,  2.90s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  10%|▉         | 37/372 [05:48<13:55,  2.49s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  10%|▉         | 37/372 [05:50<13:55,  2.49s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  10%|█         | 38/372 [05:50<12:17,  2.21s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  10%|█         | 38/372 [05:52<12:17,  2.21s/it, loss=0.19] \u001b[A\n",
      "Epoch 1/3:  10%|█         | 39/372 [05:52<11:09,  2.01s/it, loss=0.19]\u001b[A\n",
      "Epoch 1/3:  10%|█         | 39/372 [05:53<11:09,  2.01s/it, loss=0.12]\u001b[A\n",
      "Epoch 1/3:  11%|█         | 40/372 [05:53<10:19,  1.87s/it, loss=0.12]\u001b[A\n",
      "Epoch 1/3:  11%|█         | 40/372 [05:55<10:19,  1.87s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  11%|█         | 41/372 [05:55<09:46,  1.77s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  11%|█         | 41/372 [05:56<09:46,  1.77s/it, loss=0.143]\u001b[A\n",
      "Epoch 1/3:  11%|█▏        | 42/372 [05:56<09:21,  1.70s/it, loss=0.143]\u001b[A\n",
      "Epoch 1/3:  11%|█▏        | 42/372 [05:58<09:21,  1.70s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  12%|█▏        | 43/372 [05:58<09:04,  1.66s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  12%|█▏        | 43/372 [06:00<09:04,  1.66s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  12%|█▏        | 44/372 [06:00<09:42,  1.78s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  12%|█▏        | 44/372 [06:01<09:42,  1.78s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  12%|█▏        | 45/372 [06:01<09:17,  1.71s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  12%|█▏        | 45/372 [06:03<09:17,  1.71s/it, loss=0.16] \u001b[A\n",
      "Epoch 1/3:  12%|█▏        | 46/372 [06:03<08:59,  1.66s/it, loss=0.16]\u001b[A\n",
      "Epoch 1/3:  12%|█▏        | 46/372 [06:04<08:59,  1.66s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  13%|█▎        | 47/372 [06:04<08:49,  1.63s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  13%|█▎        | 47/372 [06:06<08:49,  1.63s/it, loss=0.14] \u001b[A\n",
      "Epoch 1/3:  13%|█▎        | 48/372 [06:06<08:39,  1.60s/it, loss=0.14]\u001b[A\n",
      "Epoch 1/3:  13%|█▎        | 48/372 [06:08<08:39,  1.60s/it, loss=0.143]\u001b[A\n",
      "Epoch 1/3:  13%|█▎        | 49/372 [06:08<08:31,  1.58s/it, loss=0.143]\u001b[A\n",
      "Epoch 1/3:  13%|█▎        | 49/372 [06:09<08:31,  1.58s/it, loss=0.168]\u001b[A\n",
      "Epoch 1/3:  13%|█▎        | 50/372 [06:09<08:24,  1.57s/it, loss=0.168]\u001b[A\n",
      "Epoch 1/3:  13%|█▎        | 50/372 [06:11<08:24,  1.57s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  14%|█▎        | 51/372 [06:11<08:20,  1.56s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  14%|█▎        | 51/372 [06:13<08:20,  1.56s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  14%|█▍        | 52/372 [06:13<09:53,  1.85s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  14%|█▍        | 52/372 [06:15<09:53,  1.85s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  14%|█▍        | 53/372 [06:15<09:22,  1.76s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  14%|█▍        | 53/372 [06:16<09:22,  1.76s/it, loss=0.17] \u001b[A\n",
      "Epoch 1/3:  15%|█▍        | 54/372 [06:16<08:59,  1.70s/it, loss=0.17]\u001b[A\n",
      "Epoch 1/3:  15%|█▍        | 54/372 [06:18<08:59,  1.70s/it, loss=0.157]\u001b[A\n",
      "Epoch 1/3:  15%|█▍        | 55/372 [06:18<08:41,  1.65s/it, loss=0.157]\u001b[A\n",
      "Epoch 1/3:  15%|█▍        | 55/372 [06:19<08:41,  1.65s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  15%|█▌        | 56/372 [06:19<08:31,  1.62s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  15%|█▌        | 56/372 [06:21<08:31,  1.62s/it, loss=0.12] \u001b[A\n",
      "Epoch 1/3:  15%|█▌        | 57/372 [06:21<08:19,  1.59s/it, loss=0.12]\u001b[A\n",
      "Epoch 1/3:  15%|█▌        | 57/372 [06:22<08:19,  1.59s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  16%|█▌        | 58/372 [06:22<08:13,  1.57s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  16%|█▌        | 58/372 [06:24<08:13,  1.57s/it, loss=0.152]\u001b[A\n",
      "Epoch 1/3:  16%|█▌        | 59/372 [06:24<08:09,  1.56s/it, loss=0.152]\u001b[A\n",
      "Epoch 1/3:  16%|█▌        | 59/372 [06:28<08:09,  1.56s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  16%|█▌        | 60/372 [06:28<11:23,  2.19s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  16%|█▌        | 60/372 [06:29<11:23,  2.19s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  16%|█▋        | 61/372 [06:29<10:19,  1.99s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  16%|█▋        | 61/372 [06:31<10:19,  1.99s/it, loss=0.176]\u001b[A\n",
      "Epoch 1/3:  17%|█▋        | 62/372 [06:31<09:33,  1.85s/it, loss=0.176]\u001b[A\n",
      "Epoch 1/3:  17%|█▋        | 62/372 [06:32<09:33,  1.85s/it, loss=0.11] \u001b[A\n",
      "Epoch 1/3:  17%|█▋        | 63/372 [06:32<09:02,  1.76s/it, loss=0.11]\u001b[A\n",
      "Epoch 1/3:  17%|█▋        | 63/372 [06:34<09:02,  1.76s/it, loss=0.156]\u001b[A\n",
      "Epoch 1/3:  17%|█▋        | 64/372 [06:34<08:41,  1.69s/it, loss=0.156]\u001b[A\n",
      "Epoch 1/3:  17%|█▋        | 64/372 [06:35<08:41,  1.69s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  17%|█▋        | 65/372 [06:35<08:23,  1.64s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  17%|█▋        | 65/372 [06:37<08:23,  1.64s/it, loss=0.166]\u001b[A\n",
      "Epoch 1/3:  18%|█▊        | 66/372 [06:37<08:12,  1.61s/it, loss=0.166]\u001b[A\n",
      "Epoch 1/3:  18%|█▊        | 66/372 [06:38<08:12,  1.61s/it, loss=0.14] \u001b[A\n",
      "Epoch 1/3:  18%|█▊        | 67/372 [06:38<08:02,  1.58s/it, loss=0.14]\u001b[A\n",
      "Epoch 1/3:  18%|█▊        | 67/372 [06:40<08:02,  1.58s/it, loss=0.166]\u001b[A\n",
      "Epoch 1/3:  18%|█▊        | 68/372 [06:40<08:55,  1.76s/it, loss=0.166]\u001b[A\n",
      "Epoch 1/3:  18%|█▊        | 68/372 [06:42<08:55,  1.76s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  19%|█▊        | 69/372 [06:42<08:31,  1.69s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  19%|█▊        | 69/372 [06:43<08:31,  1.69s/it, loss=0.196]\u001b[A\n",
      "Epoch 1/3:  19%|█▉        | 70/372 [06:43<08:15,  1.64s/it, loss=0.196]\u001b[A\n",
      "Epoch 1/3:  19%|█▉        | 70/372 [06:45<08:15,  1.64s/it, loss=0.154]\u001b[A\n",
      "Epoch 1/3:  19%|█▉        | 71/372 [06:45<08:02,  1.60s/it, loss=0.154]\u001b[A\n",
      "Epoch 1/3:  19%|█▉        | 71/372 [06:47<08:02,  1.60s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  19%|█▉        | 72/372 [06:47<07:53,  1.58s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  19%|█▉        | 72/372 [06:49<07:53,  1.58s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  20%|█▉        | 73/372 [06:49<09:17,  1.86s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  20%|█▉        | 73/372 [06:51<09:17,  1.86s/it, loss=0.118]\u001b[A\n",
      "Epoch 1/3:  20%|█▉        | 74/372 [06:51<08:44,  1.76s/it, loss=0.118]\u001b[A\n",
      "Epoch 1/3:  20%|█▉        | 74/372 [06:52<08:44,  1.76s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  20%|██        | 75/372 [06:52<08:20,  1.69s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  20%|██        | 75/372 [06:54<08:20,  1.69s/it, loss=0.13] \u001b[A\n",
      "Epoch 1/3:  20%|██        | 76/372 [06:54<08:05,  1.64s/it, loss=0.13]\u001b[A\n",
      "Epoch 1/3:  20%|██        | 76/372 [06:55<08:05,  1.64s/it, loss=0.184]\u001b[A\n",
      "Epoch 1/3:  21%|██        | 77/372 [06:55<07:54,  1.61s/it, loss=0.184]\u001b[A\n",
      "Epoch 1/3:  21%|██        | 77/372 [06:57<07:54,  1.61s/it, loss=0.175]\u001b[A\n",
      "Epoch 1/3:  21%|██        | 78/372 [06:57<07:46,  1.59s/it, loss=0.175]\u001b[A\n",
      "Epoch 1/3:  21%|██        | 78/372 [06:58<07:46,  1.59s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  21%|██        | 79/372 [06:58<07:36,  1.56s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  21%|██        | 79/372 [07:00<07:36,  1.56s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  22%|██▏       | 80/372 [07:00<07:32,  1.55s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  22%|██▏       | 80/372 [07:02<07:32,  1.55s/it, loss=0.173]\u001b[A\n",
      "Epoch 1/3:  22%|██▏       | 81/372 [07:02<09:12,  1.90s/it, loss=0.173]\u001b[A\n",
      "Epoch 1/3:  22%|██▏       | 81/372 [07:04<09:12,  1.90s/it, loss=0.136]\u001b[A\n",
      "Epoch 1/3:  22%|██▏       | 82/372 [07:04<08:39,  1.79s/it, loss=0.136]\u001b[A\n",
      "Epoch 1/3:  22%|██▏       | 82/372 [07:06<08:39,  1.79s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  22%|██▏       | 83/372 [07:06<08:18,  1.72s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  22%|██▏       | 83/372 [07:07<08:18,  1.72s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  23%|██▎       | 84/372 [07:07<07:58,  1.66s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  23%|██▎       | 84/372 [07:09<07:58,  1.66s/it, loss=0.15] \u001b[A\n",
      "Epoch 1/3:  23%|██▎       | 85/372 [07:09<07:45,  1.62s/it, loss=0.15]\u001b[A\n",
      "Epoch 1/3:  23%|██▎       | 85/372 [07:10<07:45,  1.62s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  23%|██▎       | 86/372 [07:10<07:35,  1.59s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  23%|██▎       | 86/372 [07:12<07:35,  1.59s/it, loss=0.148]\u001b[A\n",
      "Epoch 1/3:  23%|██▎       | 87/372 [07:12<07:28,  1.58s/it, loss=0.148]\u001b[A\n",
      "Epoch 1/3:  23%|██▎       | 87/372 [07:13<07:28,  1.58s/it, loss=0.117]\u001b[A\n",
      "Epoch 1/3:  24%|██▎       | 88/372 [07:13<07:23,  1.56s/it, loss=0.117]\u001b[A\n",
      "Epoch 1/3:  24%|██▎       | 88/372 [07:21<07:23,  1.56s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  24%|██▍       | 89/372 [07:21<16:31,  3.50s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  24%|██▍       | 89/372 [07:23<16:31,  3.50s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  24%|██▍       | 90/372 [07:23<13:42,  2.92s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  24%|██▍       | 90/372 [07:24<13:42,  2.92s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  24%|██▍       | 91/372 [07:24<11:43,  2.50s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  24%|██▍       | 91/372 [07:26<11:43,  2.50s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  25%|██▍       | 92/372 [07:26<10:17,  2.21s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  25%|██▍       | 92/372 [07:27<10:17,  2.21s/it, loss=0.168]\u001b[A\n",
      "Epoch 1/3:  25%|██▌       | 93/372 [07:27<09:20,  2.01s/it, loss=0.168]\u001b[A\n",
      "Epoch 1/3:  25%|██▌       | 93/372 [07:29<09:20,  2.01s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  25%|██▌       | 94/372 [07:29<08:38,  1.87s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  25%|██▌       | 94/372 [07:30<08:38,  1.87s/it, loss=0.152]\u001b[A\n",
      "Epoch 1/3:  26%|██▌       | 95/372 [07:30<08:10,  1.77s/it, loss=0.152]\u001b[A\n",
      "Epoch 1/3:  26%|██▌       | 95/372 [07:32<08:10,  1.77s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  26%|██▌       | 96/372 [07:32<07:50,  1.70s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  26%|██▌       | 96/372 [07:39<07:50,  1.70s/it, loss=0.0966]\u001b[A\n",
      "Epoch 1/3:  26%|██▌       | 97/372 [07:39<14:40,  3.20s/it, loss=0.0966]\u001b[A\n",
      "Epoch 1/3:  26%|██▌       | 97/372 [07:40<14:40,  3.20s/it, loss=0.128] \u001b[A\n",
      "Epoch 1/3:  26%|██▋       | 98/372 [07:40<12:21,  2.71s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  26%|██▋       | 98/372 [07:42<12:21,  2.71s/it, loss=0.172]\u001b[A\n",
      "Epoch 1/3:  27%|██▋       | 99/372 [07:42<10:43,  2.36s/it, loss=0.172]\u001b[A\n",
      "Epoch 1/3:  27%|██▋       | 99/372 [07:43<10:43,  2.36s/it, loss=0.133]\u001b[A\n",
      "Epoch 1/3:  27%|██▋       | 100/372 [07:43<09:34,  2.11s/it, loss=0.133]\u001b[A\n",
      "Epoch 1/3:  27%|██▋       | 100/372 [07:45<09:34,  2.11s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  27%|██▋       | 101/372 [07:45<08:44,  1.94s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  27%|██▋       | 101/372 [07:46<08:44,  1.94s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  27%|██▋       | 102/372 [07:46<08:10,  1.82s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  27%|██▋       | 102/372 [07:48<08:10,  1.82s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  28%|██▊       | 103/372 [07:48<07:47,  1.74s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  28%|██▊       | 103/372 [07:49<07:47,  1.74s/it, loss=0.13] \u001b[A\n",
      "Epoch 1/3:  28%|██▊       | 104/372 [07:49<07:30,  1.68s/it, loss=0.13]\u001b[A\n",
      "Epoch 1/3:  28%|██▊       | 104/372 [07:55<07:30,  1.68s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  28%|██▊       | 105/372 [07:55<12:03,  2.71s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  28%|██▊       | 105/372 [07:56<12:03,  2.71s/it, loss=0.0895]\u001b[A\n",
      "Epoch 1/3:  28%|██▊       | 106/372 [07:56<10:25,  2.35s/it, loss=0.0895]\u001b[A\n",
      "Epoch 1/3:  28%|██▊       | 106/372 [07:58<10:25,  2.35s/it, loss=0.116] \u001b[A\n",
      "Epoch 1/3:  29%|██▉       | 107/372 [07:58<09:19,  2.11s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  29%|██▉       | 107/372 [07:59<09:19,  2.11s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  29%|██▉       | 108/372 [07:59<08:32,  1.94s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  29%|██▉       | 108/372 [08:01<08:32,  1.94s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  29%|██▉       | 109/372 [08:01<07:59,  1.82s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  29%|██▉       | 109/372 [08:02<07:59,  1.82s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  30%|██▉       | 110/372 [08:02<07:34,  1.74s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  30%|██▉       | 110/372 [08:04<07:34,  1.74s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  30%|██▉       | 111/372 [08:04<07:18,  1.68s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  30%|██▉       | 111/372 [08:05<07:18,  1.68s/it, loss=0.176]\u001b[A\n",
      "Epoch 1/3:  30%|███       | 112/372 [08:05<07:06,  1.64s/it, loss=0.176]\u001b[A\n",
      "Epoch 1/3:  30%|███       | 112/372 [08:08<07:06,  1.64s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  30%|███       | 113/372 [08:08<09:00,  2.09s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  30%|███       | 113/372 [08:10<09:00,  2.09s/it, loss=0.0994]\u001b[A\n",
      "Epoch 1/3:  31%|███       | 114/372 [08:10<08:14,  1.92s/it, loss=0.0994]\u001b[A\n",
      "Epoch 1/3:  31%|███       | 114/372 [08:12<08:14,  1.92s/it, loss=0.162] \u001b[A\n",
      "Epoch 1/3:  31%|███       | 115/372 [08:12<07:43,  1.80s/it, loss=0.162]\u001b[A\n",
      "Epoch 1/3:  31%|███       | 115/372 [08:13<07:43,  1.80s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  31%|███       | 116/372 [08:13<07:20,  1.72s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  31%|███       | 116/372 [08:15<07:20,  1.72s/it, loss=0.162]\u001b[A\n",
      "Epoch 1/3:  31%|███▏      | 117/372 [08:15<07:02,  1.66s/it, loss=0.162]\u001b[A\n",
      "Epoch 1/3:  31%|███▏      | 117/372 [08:16<07:02,  1.66s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  32%|███▏      | 118/372 [08:16<06:52,  1.63s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  32%|███▏      | 118/372 [08:18<06:52,  1.63s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  32%|███▏      | 119/372 [08:18<06:42,  1.59s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  32%|███▏      | 119/372 [08:19<06:42,  1.59s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  32%|███▏      | 120/372 [08:19<06:37,  1.58s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  32%|███▏      | 120/372 [08:26<06:37,  1.58s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  33%|███▎      | 121/372 [08:26<12:54,  3.08s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  33%|███▎      | 121/372 [08:27<12:54,  3.08s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  33%|███▎      | 122/372 [08:27<10:54,  2.62s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  33%|███▎      | 122/372 [08:29<10:54,  2.62s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  33%|███▎      | 123/372 [08:29<09:30,  2.29s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  33%|███▎      | 123/372 [08:30<09:30,  2.29s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  33%|███▎      | 124/372 [08:30<08:31,  2.06s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  33%|███▎      | 124/372 [08:32<08:31,  2.06s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  34%|███▎      | 125/372 [08:32<07:49,  1.90s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  34%|███▎      | 125/372 [08:33<07:49,  1.90s/it, loss=0.148]\u001b[A\n",
      "Epoch 1/3:  34%|███▍      | 126/372 [08:33<07:20,  1.79s/it, loss=0.148]\u001b[A\n",
      "Epoch 1/3:  34%|███▍      | 126/372 [08:35<07:20,  1.79s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  34%|███▍      | 127/372 [08:35<06:58,  1.71s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  34%|███▍      | 127/372 [08:36<06:58,  1.71s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  34%|███▍      | 128/372 [08:36<06:44,  1.66s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  34%|███▍      | 128/372 [08:39<06:44,  1.66s/it, loss=0.154]\u001b[A\n",
      "Epoch 1/3:  35%|███▍      | 129/372 [08:39<07:57,  1.97s/it, loss=0.154]\u001b[A\n",
      "Epoch 1/3:  35%|███▍      | 129/372 [08:41<07:57,  1.97s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  35%|███▍      | 130/372 [08:41<07:24,  1.84s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  35%|███▍      | 130/372 [08:42<07:24,  1.84s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  35%|███▌      | 131/372 [08:42<07:00,  1.74s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  35%|███▌      | 131/372 [08:44<07:00,  1.74s/it, loss=0.104]\u001b[A\n",
      "Epoch 1/3:  35%|███▌      | 132/372 [08:44<06:44,  1.68s/it, loss=0.104]\u001b[A\n",
      "Epoch 1/3:  35%|███▌      | 132/372 [08:45<06:44,  1.68s/it, loss=0.133]\u001b[A\n",
      "Epoch 1/3:  36%|███▌      | 133/372 [08:45<06:31,  1.64s/it, loss=0.133]\u001b[A\n",
      "Epoch 1/3:  36%|███▌      | 133/372 [08:47<06:31,  1.64s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  36%|███▌      | 134/372 [08:47<06:22,  1.61s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  36%|███▌      | 134/372 [08:48<06:22,  1.61s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  36%|███▋      | 135/372 [08:48<06:16,  1.59s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  36%|███▋      | 135/372 [08:50<06:16,  1.59s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  37%|███▋      | 136/372 [08:50<06:10,  1.57s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  37%|███▋      | 136/372 [08:54<06:10,  1.57s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  37%|███▋      | 137/372 [08:54<09:23,  2.40s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  37%|███▋      | 137/372 [08:56<09:23,  2.40s/it, loss=0.13] \u001b[A\n",
      "Epoch 1/3:  37%|███▋      | 138/372 [08:56<08:20,  2.14s/it, loss=0.13]\u001b[A\n",
      "Epoch 1/3:  37%|███▋      | 138/372 [08:57<08:20,  2.14s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  37%|███▋      | 139/372 [08:57<07:35,  1.96s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  37%|███▋      | 139/372 [08:59<07:35,  1.96s/it, loss=0.0943]\u001b[A\n",
      "Epoch 1/3:  38%|███▊      | 140/372 [08:59<07:04,  1.83s/it, loss=0.0943]\u001b[A\n",
      "Epoch 1/3:  38%|███▊      | 140/372 [09:00<07:04,  1.83s/it, loss=0.125] \u001b[A\n",
      "Epoch 1/3:  38%|███▊      | 141/372 [09:00<06:40,  1.73s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  38%|███▊      | 141/372 [09:02<06:40,  1.73s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  38%|███▊      | 142/372 [09:02<06:24,  1.67s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  38%|███▊      | 142/372 [09:03<06:24,  1.67s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  38%|███▊      | 143/372 [09:03<06:15,  1.64s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  38%|███▊      | 143/372 [09:05<06:15,  1.64s/it, loss=0.188]\u001b[A\n",
      "Epoch 1/3:  39%|███▊      | 144/372 [09:05<06:05,  1.60s/it, loss=0.188]\u001b[A\n",
      "Epoch 1/3:  39%|███▊      | 144/372 [09:07<06:05,  1.60s/it, loss=0.117]\u001b[A\n",
      "Epoch 1/3:  39%|███▉      | 145/372 [09:07<06:19,  1.67s/it, loss=0.117]\u001b[A\n",
      "Epoch 1/3:  39%|███▉      | 145/372 [09:08<06:19,  1.67s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:  39%|███▉      | 146/372 [09:08<06:08,  1.63s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:  39%|███▉      | 146/372 [09:10<06:08,  1.63s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  40%|███▉      | 147/372 [09:10<06:00,  1.60s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  40%|███▉      | 147/372 [09:11<06:00,  1.60s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  40%|███▉      | 148/372 [09:11<05:54,  1.58s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  40%|███▉      | 148/372 [09:13<05:54,  1.58s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  40%|████      | 149/372 [09:13<05:49,  1.57s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  40%|████      | 149/372 [09:14<05:49,  1.57s/it, loss=0.163]\u001b[A\n",
      "Epoch 1/3:  40%|████      | 150/372 [09:14<05:46,  1.56s/it, loss=0.163]\u001b[A\n",
      "Epoch 1/3:  40%|████      | 150/372 [09:16<05:46,  1.56s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  41%|████      | 151/372 [09:16<05:43,  1.56s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  41%|████      | 151/372 [09:18<05:43,  1.56s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  41%|████      | 152/372 [09:18<05:40,  1.55s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  41%|████      | 152/372 [09:21<05:40,  1.55s/it, loss=0.175]\u001b[A\n",
      "Epoch 1/3:  41%|████      | 153/372 [09:21<07:26,  2.04s/it, loss=0.175]\u001b[A\n",
      "Epoch 1/3:  41%|████      | 153/372 [09:22<07:26,  2.04s/it, loss=0.102]\u001b[A\n",
      "Epoch 1/3:  41%|████▏     | 154/372 [09:22<06:50,  1.88s/it, loss=0.102]\u001b[A\n",
      "Epoch 1/3:  41%|████▏     | 154/372 [09:24<06:50,  1.88s/it, loss=0.136]\u001b[A\n",
      "Epoch 1/3:  42%|████▏     | 155/372 [09:24<06:25,  1.78s/it, loss=0.136]\u001b[A\n",
      "Epoch 1/3:  42%|████▏     | 155/372 [09:25<06:25,  1.78s/it, loss=0.151]\u001b[A\n",
      "Epoch 1/3:  42%|████▏     | 156/372 [09:25<06:08,  1.70s/it, loss=0.151]\u001b[A\n",
      "Epoch 1/3:  42%|████▏     | 156/372 [09:27<06:08,  1.70s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  42%|████▏     | 157/372 [09:27<05:55,  1.65s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  42%|████▏     | 157/372 [09:28<05:55,  1.65s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  42%|████▏     | 158/372 [09:28<05:46,  1.62s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  42%|████▏     | 158/372 [09:30<05:46,  1.62s/it, loss=0.0981]\u001b[A\n",
      "Epoch 1/3:  43%|████▎     | 159/372 [09:30<05:40,  1.60s/it, loss=0.0981]\u001b[A\n",
      "Epoch 1/3:  43%|████▎     | 159/372 [09:31<05:40,  1.60s/it, loss=0.119] \u001b[A\n",
      "Epoch 1/3:  43%|████▎     | 160/372 [09:31<05:34,  1.58s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  43%|████▎     | 160/372 [09:34<05:34,  1.58s/it, loss=0.105]\u001b[A\n",
      "Epoch 1/3:  43%|████▎     | 161/372 [09:34<06:28,  1.84s/it, loss=0.105]\u001b[A\n",
      "Epoch 1/3:  43%|████▎     | 161/372 [09:36<06:28,  1.84s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  44%|████▎     | 162/372 [09:36<06:08,  1.76s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  44%|████▎     | 162/372 [09:37<06:08,  1.76s/it, loss=0.123]\u001b[A\n",
      "Epoch 1/3:  44%|████▍     | 163/372 [09:37<05:53,  1.69s/it, loss=0.123]\u001b[A\n",
      "Epoch 1/3:  44%|████▍     | 163/372 [09:39<05:53,  1.69s/it, loss=0.204]\u001b[A\n",
      "Epoch 1/3:  44%|████▍     | 164/372 [09:39<05:43,  1.65s/it, loss=0.204]\u001b[A\n",
      "Epoch 1/3:  44%|████▍     | 164/372 [09:40<05:43,  1.65s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  44%|████▍     | 165/372 [09:40<05:36,  1.62s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  44%|████▍     | 165/372 [09:42<05:36,  1.62s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  45%|████▍     | 166/372 [09:42<05:27,  1.59s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  45%|████▍     | 166/372 [09:43<05:27,  1.59s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  45%|████▍     | 167/372 [09:43<05:23,  1.58s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  45%|████▍     | 167/372 [09:45<05:23,  1.58s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  45%|████▌     | 168/372 [09:45<05:19,  1.57s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  45%|████▌     | 168/372 [09:46<05:19,  1.57s/it, loss=0.143]\u001b[A\n",
      "Epoch 1/3:  45%|████▌     | 169/372 [09:46<05:15,  1.56s/it, loss=0.143]\u001b[A\n",
      "Epoch 1/3:  45%|████▌     | 169/372 [09:48<05:15,  1.56s/it, loss=0.16] \u001b[A\n",
      "Epoch 1/3:  46%|████▌     | 170/372 [09:48<05:13,  1.55s/it, loss=0.16]\u001b[A\n",
      "Epoch 1/3:  46%|████▌     | 170/372 [09:49<05:13,  1.55s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  46%|████▌     | 171/372 [09:49<05:10,  1.55s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  46%|████▌     | 171/372 [09:51<05:10,  1.55s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  46%|████▌     | 172/372 [09:51<05:08,  1.54s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  46%|████▌     | 172/372 [09:52<05:08,  1.54s/it, loss=0.0894]\u001b[A\n",
      "Epoch 1/3:  47%|████▋     | 173/372 [09:52<05:06,  1.54s/it, loss=0.0894]\u001b[A\n",
      "Epoch 1/3:  47%|████▋     | 173/372 [09:54<05:06,  1.54s/it, loss=0.111] \u001b[A\n",
      "Epoch 1/3:  47%|████▋     | 174/372 [09:54<05:05,  1.54s/it, loss=0.111]\u001b[A\n",
      "Epoch 1/3:  47%|████▋     | 174/372 [09:56<05:05,  1.54s/it, loss=0.179]\u001b[A\n",
      "Epoch 1/3:  47%|████▋     | 175/372 [09:56<05:04,  1.54s/it, loss=0.179]\u001b[A\n",
      "Epoch 1/3:  47%|████▋     | 175/372 [09:57<05:04,  1.54s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  47%|████▋     | 176/372 [09:57<05:03,  1.55s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  47%|████▋     | 176/372 [09:59<05:03,  1.55s/it, loss=0.123]\u001b[A\n",
      "Epoch 1/3:  48%|████▊     | 177/372 [09:59<05:41,  1.75s/it, loss=0.123]\u001b[A\n",
      "Epoch 1/3:  48%|████▊     | 177/372 [10:01<05:41,  1.75s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  48%|████▊     | 178/372 [10:01<05:27,  1.69s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  48%|████▊     | 178/372 [10:02<05:27,  1.69s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  48%|████▊     | 179/372 [10:02<05:16,  1.64s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  48%|████▊     | 179/372 [10:04<05:16,  1.64s/it, loss=0.177]\u001b[A\n",
      "Epoch 1/3:  48%|████▊     | 180/372 [10:04<05:08,  1.61s/it, loss=0.177]\u001b[A\n",
      "Epoch 1/3:  48%|████▊     | 180/372 [10:05<05:08,  1.61s/it, loss=0.175]\u001b[A\n",
      "Epoch 1/3:  49%|████▊     | 181/372 [10:05<05:02,  1.58s/it, loss=0.175]\u001b[A\n",
      "Epoch 1/3:  49%|████▊     | 181/372 [10:07<05:02,  1.58s/it, loss=0.173]\u001b[A\n",
      "Epoch 1/3:  49%|████▉     | 182/372 [10:07<04:57,  1.56s/it, loss=0.173]\u001b[A\n",
      "Epoch 1/3:  49%|████▉     | 182/372 [10:09<04:57,  1.56s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  49%|████▉     | 183/372 [10:09<04:54,  1.56s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  49%|████▉     | 183/372 [10:10<04:54,  1.56s/it, loss=0.147]\u001b[A\n",
      "Epoch 1/3:  49%|████▉     | 184/372 [10:10<04:50,  1.55s/it, loss=0.147]\u001b[A\n",
      "Epoch 1/3:  49%|████▉     | 184/372 [10:12<04:50,  1.55s/it, loss=0.111]\u001b[A\n",
      "Epoch 1/3:  50%|████▉     | 185/372 [10:12<04:48,  1.54s/it, loss=0.111]\u001b[A\n",
      "Epoch 1/3:  50%|████▉     | 185/372 [10:13<04:48,  1.54s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  50%|█████     | 186/372 [10:13<04:47,  1.55s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  50%|█████     | 186/372 [10:15<04:47,  1.55s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  50%|█████     | 187/372 [10:15<04:45,  1.54s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  50%|█████     | 187/372 [10:16<04:45,  1.54s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  51%|█████     | 188/372 [10:16<04:43,  1.54s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  51%|█████     | 188/372 [10:18<04:43,  1.54s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  51%|█████     | 189/372 [10:18<04:41,  1.54s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  51%|█████     | 189/372 [10:19<04:41,  1.54s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:  51%|█████     | 190/372 [10:19<04:39,  1.54s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:  51%|█████     | 190/372 [10:21<04:39,  1.54s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  51%|█████▏    | 191/372 [10:21<04:37,  1.54s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  51%|█████▏    | 191/372 [10:22<04:37,  1.54s/it, loss=0.182]\u001b[A\n",
      "Epoch 1/3:  52%|█████▏    | 192/372 [10:22<04:36,  1.53s/it, loss=0.182]\u001b[A\n",
      "Epoch 1/3:  52%|█████▏    | 192/372 [10:26<04:36,  1.53s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  52%|█████▏    | 193/372 [10:26<06:47,  2.27s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  52%|█████▏    | 193/372 [10:28<06:47,  2.27s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  52%|█████▏    | 194/372 [10:28<06:05,  2.05s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  52%|█████▏    | 194/372 [10:29<06:05,  2.05s/it, loss=0.124]\u001b[A\n",
      "Epoch 1/3:  52%|█████▏    | 195/372 [10:29<05:35,  1.90s/it, loss=0.124]\u001b[A\n",
      "Epoch 1/3:  52%|█████▏    | 195/372 [10:31<05:35,  1.90s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  53%|█████▎    | 196/372 [10:31<05:14,  1.79s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  53%|█████▎    | 196/372 [10:32<05:14,  1.79s/it, loss=0.093]\u001b[A\n",
      "Epoch 1/3:  53%|█████▎    | 197/372 [10:32<04:59,  1.71s/it, loss=0.093]\u001b[A\n",
      "Epoch 1/3:  53%|█████▎    | 197/372 [10:34<04:59,  1.71s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  53%|█████▎    | 198/372 [10:34<04:47,  1.65s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  53%|█████▎    | 198/372 [10:36<04:47,  1.65s/it, loss=0.15] \u001b[A\n",
      "Epoch 1/3:  53%|█████▎    | 199/372 [10:36<04:39,  1.62s/it, loss=0.15]\u001b[A\n",
      "Epoch 1/3:  53%|█████▎    | 199/372 [10:37<04:39,  1.62s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  54%|█████▍    | 200/372 [10:37<04:35,  1.60s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  54%|█████▍    | 200/372 [10:39<04:35,  1.60s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  54%|█████▍    | 201/372 [10:39<04:30,  1.58s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  54%|█████▍    | 201/372 [10:40<04:30,  1.58s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  54%|█████▍    | 202/372 [10:40<04:26,  1.56s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  54%|█████▍    | 202/372 [10:42<04:26,  1.56s/it, loss=0.14] \u001b[A\n",
      "Epoch 1/3:  55%|█████▍    | 203/372 [10:42<04:23,  1.56s/it, loss=0.14]\u001b[A\n",
      "Epoch 1/3:  55%|█████▍    | 203/372 [10:43<04:23,  1.56s/it, loss=0.167]\u001b[A\n",
      "Epoch 1/3:  55%|█████▍    | 204/372 [10:43<04:21,  1.56s/it, loss=0.167]\u001b[A\n",
      "Epoch 1/3:  55%|█████▍    | 204/372 [10:45<04:21,  1.56s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  55%|█████▌    | 205/372 [10:45<04:19,  1.55s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  55%|█████▌    | 205/372 [10:46<04:19,  1.55s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  55%|█████▌    | 206/372 [10:46<04:16,  1.54s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  55%|█████▌    | 206/372 [10:48<04:16,  1.54s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  56%|█████▌    | 207/372 [10:48<04:14,  1.54s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  56%|█████▌    | 207/372 [10:49<04:14,  1.54s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  56%|█████▌    | 208/372 [10:49<04:12,  1.54s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  56%|█████▌    | 208/372 [10:51<04:12,  1.54s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  56%|█████▌    | 209/372 [10:51<04:40,  1.72s/it, loss=0.142]\u001b[A\n",
      "Epoch 1/3:  56%|█████▌    | 209/372 [10:53<04:40,  1.72s/it, loss=0.152]\u001b[A\n",
      "Epoch 1/3:  56%|█████▋    | 210/372 [10:53<04:29,  1.67s/it, loss=0.152]\u001b[A\n",
      "Epoch 1/3:  56%|█████▋    | 210/372 [10:55<04:29,  1.67s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  57%|█████▋    | 211/372 [10:55<04:21,  1.63s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  57%|█████▋    | 211/372 [10:56<04:21,  1.63s/it, loss=0.131]\u001b[A\n",
      "Epoch 1/3:  57%|█████▋    | 212/372 [10:56<04:16,  1.60s/it, loss=0.131]\u001b[A\n",
      "Epoch 1/3:  57%|█████▋    | 212/372 [10:58<04:16,  1.60s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  57%|█████▋    | 213/372 [10:58<04:11,  1.58s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  57%|█████▋    | 213/372 [10:59<04:11,  1.58s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  58%|█████▊    | 214/372 [10:59<04:07,  1.57s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  58%|█████▊    | 214/372 [11:01<04:07,  1.57s/it, loss=0.11] \u001b[A\n",
      "Epoch 1/3:  58%|█████▊    | 215/372 [11:01<04:04,  1.56s/it, loss=0.11]\u001b[A\n",
      "Epoch 1/3:  58%|█████▊    | 215/372 [11:02<04:04,  1.56s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  58%|█████▊    | 216/372 [11:02<04:02,  1.55s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  58%|█████▊    | 216/372 [11:05<04:02,  1.55s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  58%|█████▊    | 217/372 [11:05<05:15,  2.04s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  58%|█████▊    | 217/372 [11:07<05:15,  2.04s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  59%|█████▊    | 218/372 [11:07<04:50,  1.88s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  59%|█████▊    | 218/372 [11:08<04:50,  1.88s/it, loss=0.124]\u001b[A\n",
      "Epoch 1/3:  59%|█████▉    | 219/372 [11:08<04:31,  1.78s/it, loss=0.124]\u001b[A\n",
      "Epoch 1/3:  59%|█████▉    | 219/372 [11:10<04:31,  1.78s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  59%|█████▉    | 220/372 [11:10<04:18,  1.70s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  59%|█████▉    | 220/372 [11:12<04:18,  1.70s/it, loss=0.145]\u001b[A\n",
      "Epoch 1/3:  59%|█████▉    | 221/372 [11:12<04:10,  1.66s/it, loss=0.145]\u001b[A\n",
      "Epoch 1/3:  59%|█████▉    | 221/372 [11:13<04:10,  1.66s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  60%|█████▉    | 222/372 [11:13<04:03,  1.62s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  60%|█████▉    | 222/372 [11:15<04:03,  1.62s/it, loss=0.117]\u001b[A\n",
      "Epoch 1/3:  60%|█████▉    | 223/372 [11:15<03:57,  1.59s/it, loss=0.117]\u001b[A\n",
      "Epoch 1/3:  60%|█████▉    | 223/372 [11:16<03:57,  1.59s/it, loss=0.0937]\u001b[A\n",
      "Epoch 1/3:  60%|██████    | 224/372 [11:16<03:53,  1.58s/it, loss=0.0937]\u001b[A\n",
      "Epoch 1/3:  60%|██████    | 224/372 [11:18<03:53,  1.58s/it, loss=0.14]  \u001b[A\n",
      "Epoch 1/3:  60%|██████    | 225/372 [11:18<04:06,  1.68s/it, loss=0.14]\u001b[A\n",
      "Epoch 1/3:  60%|██████    | 225/372 [11:20<04:06,  1.68s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  61%|██████    | 226/372 [11:20<03:59,  1.64s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  61%|██████    | 226/372 [11:21<03:59,  1.64s/it, loss=0.154]\u001b[A\n",
      "Epoch 1/3:  61%|██████    | 227/372 [11:21<03:53,  1.61s/it, loss=0.154]\u001b[A\n",
      "Epoch 1/3:  61%|██████    | 227/372 [11:23<03:53,  1.61s/it, loss=0.0942]\u001b[A\n",
      "Epoch 1/3:  61%|██████▏   | 228/372 [11:23<03:48,  1.59s/it, loss=0.0942]\u001b[A\n",
      "Epoch 1/3:  61%|██████▏   | 228/372 [11:24<03:48,  1.59s/it, loss=0.0721]\u001b[A\n",
      "Epoch 1/3:  62%|██████▏   | 229/372 [11:24<03:44,  1.57s/it, loss=0.0721]\u001b[A\n",
      "Epoch 1/3:  62%|██████▏   | 229/372 [11:26<03:44,  1.57s/it, loss=0.115] \u001b[A\n",
      "Epoch 1/3:  62%|██████▏   | 230/372 [11:26<03:41,  1.56s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  62%|██████▏   | 230/372 [11:27<03:41,  1.56s/it, loss=0.103]\u001b[A\n",
      "Epoch 1/3:  62%|██████▏   | 231/372 [11:27<03:38,  1.55s/it, loss=0.103]\u001b[A\n",
      "Epoch 1/3:  62%|██████▏   | 231/372 [11:29<03:38,  1.55s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  62%|██████▏   | 232/372 [11:29<03:35,  1.54s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  62%|██████▏   | 232/372 [11:31<03:35,  1.54s/it, loss=0.191]\u001b[A\n",
      "Epoch 1/3:  63%|██████▎   | 233/372 [11:31<03:55,  1.69s/it, loss=0.191]\u001b[A\n",
      "Epoch 1/3:  63%|██████▎   | 233/372 [11:32<03:55,  1.69s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  63%|██████▎   | 234/372 [11:32<03:46,  1.64s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  63%|██████▎   | 234/372 [11:34<03:46,  1.64s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  63%|██████▎   | 235/372 [11:34<03:40,  1.61s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  63%|██████▎   | 235/372 [11:35<03:40,  1.61s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  63%|██████▎   | 236/372 [11:35<03:35,  1.59s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  63%|██████▎   | 236/372 [11:37<03:35,  1.59s/it, loss=0.162]\u001b[A\n",
      "Epoch 1/3:  64%|██████▎   | 237/372 [11:37<03:31,  1.57s/it, loss=0.162]\u001b[A\n",
      "Epoch 1/3:  64%|██████▎   | 237/372 [11:39<03:31,  1.57s/it, loss=0.133]\u001b[A\n",
      "Epoch 1/3:  64%|██████▍   | 238/372 [11:39<03:28,  1.56s/it, loss=0.133]\u001b[A\n",
      "Epoch 1/3:  64%|██████▍   | 238/372 [11:40<03:28,  1.56s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  64%|██████▍   | 239/372 [11:40<03:25,  1.55s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  64%|██████▍   | 239/372 [11:42<03:25,  1.55s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  65%|██████▍   | 240/372 [11:42<03:23,  1.54s/it, loss=0.146]\u001b[A\n",
      "Epoch 1/3:  65%|██████▍   | 240/372 [11:43<03:23,  1.54s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  65%|██████▍   | 241/372 [11:43<03:21,  1.53s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  65%|██████▍   | 241/372 [11:45<03:21,  1.53s/it, loss=0.123]\u001b[A\n",
      "Epoch 1/3:  65%|██████▌   | 242/372 [11:45<03:18,  1.53s/it, loss=0.123]\u001b[A\n",
      "Epoch 1/3:  65%|██████▌   | 242/372 [11:46<03:18,  1.53s/it, loss=0.184]\u001b[A\n",
      "Epoch 1/3:  65%|██████▌   | 243/372 [11:46<03:16,  1.52s/it, loss=0.184]\u001b[A\n",
      "Epoch 1/3:  65%|██████▌   | 243/372 [11:48<03:16,  1.52s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  66%|██████▌   | 244/372 [11:48<03:14,  1.52s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  66%|██████▌   | 244/372 [11:49<03:14,  1.52s/it, loss=0.148]\u001b[A\n",
      "Epoch 1/3:  66%|██████▌   | 245/372 [11:49<03:12,  1.52s/it, loss=0.148]\u001b[A\n",
      "Epoch 1/3:  66%|██████▌   | 245/372 [11:51<03:12,  1.52s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  66%|██████▌   | 246/372 [11:51<03:11,  1.52s/it, loss=0.134]\u001b[A\n",
      "Epoch 1/3:  66%|██████▌   | 246/372 [11:52<03:11,  1.52s/it, loss=0.169]\u001b[A\n",
      "Epoch 1/3:  66%|██████▋   | 247/372 [11:52<03:09,  1.52s/it, loss=0.169]\u001b[A\n",
      "Epoch 1/3:  66%|██████▋   | 247/372 [11:56<03:09,  1.52s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  67%|██████▋   | 248/372 [11:56<04:15,  2.06s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  67%|██████▋   | 248/372 [11:57<04:15,  2.06s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  67%|██████▋   | 249/372 [11:57<03:53,  1.90s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  67%|██████▋   | 249/372 [11:59<03:53,  1.90s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  67%|██████▋   | 250/372 [11:59<03:37,  1.79s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  67%|██████▋   | 250/372 [12:00<03:37,  1.79s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  67%|██████▋   | 251/372 [12:00<03:26,  1.71s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  67%|██████▋   | 251/372 [12:02<03:26,  1.71s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  68%|██████▊   | 252/372 [12:02<03:17,  1.65s/it, loss=0.149]\u001b[A\n",
      "Epoch 1/3:  68%|██████▊   | 252/372 [12:03<03:17,  1.65s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  68%|██████▊   | 253/372 [12:03<03:11,  1.61s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  68%|██████▊   | 253/372 [12:05<03:11,  1.61s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  68%|██████▊   | 254/372 [12:05<03:06,  1.58s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  68%|██████▊   | 254/372 [12:06<03:06,  1.58s/it, loss=0.108]\u001b[A\n",
      "Epoch 1/3:  69%|██████▊   | 255/372 [12:06<03:03,  1.57s/it, loss=0.108]\u001b[A\n",
      "Epoch 1/3:  69%|██████▊   | 255/372 [12:12<03:03,  1.57s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  69%|██████▉   | 256/372 [12:12<05:41,  2.94s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  69%|██████▉   | 256/372 [12:14<05:41,  2.94s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  69%|██████▉   | 257/372 [12:14<04:49,  2.51s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  69%|██████▉   | 257/372 [12:15<04:49,  2.51s/it, loss=0.0931]\u001b[A\n",
      "Epoch 1/3:  69%|██████▉   | 258/372 [12:15<04:13,  2.22s/it, loss=0.0931]\u001b[A\n",
      "Epoch 1/3:  69%|██████▉   | 258/372 [12:17<04:13,  2.22s/it, loss=0.11]  \u001b[A\n",
      "Epoch 1/3:  70%|██████▉   | 259/372 [12:17<03:46,  2.00s/it, loss=0.11]\u001b[A\n",
      "Epoch 1/3:  70%|██████▉   | 259/372 [12:18<03:46,  2.00s/it, loss=0.152]\u001b[A\n",
      "Epoch 1/3:  70%|██████▉   | 260/372 [12:18<03:27,  1.85s/it, loss=0.152]\u001b[A\n",
      "Epoch 1/3:  70%|██████▉   | 260/372 [12:20<03:27,  1.85s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  70%|███████   | 261/372 [12:20<03:13,  1.75s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  70%|███████   | 261/372 [12:21<03:13,  1.75s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  70%|███████   | 262/372 [12:21<03:04,  1.68s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  70%|███████   | 262/372 [12:23<03:04,  1.68s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  71%|███████   | 263/372 [12:23<02:57,  1.63s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  71%|███████   | 263/372 [12:25<02:57,  1.63s/it, loss=0.104]\u001b[A\n",
      "Epoch 1/3:  71%|███████   | 264/372 [12:25<03:06,  1.72s/it, loss=0.104]\u001b[A\n",
      "Epoch 1/3:  71%|███████   | 264/372 [12:26<03:06,  1.72s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  71%|███████   | 265/372 [12:26<02:57,  1.66s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  71%|███████   | 265/372 [12:28<02:57,  1.66s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  72%|███████▏  | 266/372 [12:28<02:51,  1.61s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  72%|███████▏  | 266/372 [12:29<02:51,  1.61s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  72%|███████▏  | 267/372 [12:29<02:46,  1.59s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  72%|███████▏  | 267/372 [12:31<02:46,  1.59s/it, loss=0.204]\u001b[A\n",
      "Epoch 1/3:  72%|███████▏  | 268/372 [12:31<02:42,  1.57s/it, loss=0.204]\u001b[A\n",
      "Epoch 1/3:  72%|███████▏  | 268/372 [12:32<02:42,  1.57s/it, loss=0.0864]\u001b[A\n",
      "Epoch 1/3:  72%|███████▏  | 269/372 [12:32<02:40,  1.56s/it, loss=0.0864]\u001b[A\n",
      "Epoch 1/3:  72%|███████▏  | 269/372 [12:34<02:40,  1.56s/it, loss=0.0849]\u001b[A\n",
      "Epoch 1/3:  73%|███████▎  | 270/372 [12:34<02:38,  1.56s/it, loss=0.0849]\u001b[A\n",
      "Epoch 1/3:  73%|███████▎  | 270/372 [12:36<02:38,  1.56s/it, loss=0.169] \u001b[A\n",
      "Epoch 1/3:  73%|███████▎  | 271/372 [12:36<02:37,  1.55s/it, loss=0.169]\u001b[A\n",
      "Epoch 1/3:  73%|███████▎  | 271/372 [12:38<02:37,  1.55s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  73%|███████▎  | 272/372 [12:38<02:59,  1.80s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  73%|███████▎  | 272/372 [12:39<02:59,  1.80s/it, loss=0.168]\u001b[A\n",
      "Epoch 1/3:  73%|███████▎  | 273/372 [12:39<02:50,  1.72s/it, loss=0.168]\u001b[A\n",
      "Epoch 1/3:  73%|███████▎  | 273/372 [12:41<02:50,  1.72s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  74%|███████▎  | 274/372 [12:41<02:42,  1.66s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  74%|███████▎  | 274/372 [12:42<02:42,  1.66s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  74%|███████▍  | 275/372 [12:42<02:36,  1.61s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  74%|███████▍  | 275/372 [12:44<02:36,  1.61s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  74%|███████▍  | 276/372 [12:44<02:32,  1.58s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  74%|███████▍  | 276/372 [12:45<02:32,  1.58s/it, loss=0.104]\u001b[A\n",
      "Epoch 1/3:  74%|███████▍  | 277/372 [12:45<02:28,  1.56s/it, loss=0.104]\u001b[A\n",
      "Epoch 1/3:  74%|███████▍  | 277/372 [12:49<02:28,  1.56s/it, loss=0.101]\u001b[A\n",
      "Epoch 1/3:  75%|███████▍  | 278/372 [12:49<03:22,  2.15s/it, loss=0.101]\u001b[A\n",
      "Epoch 1/3:  75%|███████▍  | 278/372 [12:51<03:22,  2.15s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  75%|███████▌  | 279/372 [12:51<03:02,  1.96s/it, loss=0.153]\u001b[A\n",
      "Epoch 1/3:  75%|███████▌  | 279/372 [12:57<03:02,  1.96s/it, loss=0.172]\u001b[A\n",
      "Epoch 1/3:  75%|███████▌  | 280/372 [12:57<05:00,  3.27s/it, loss=0.172]\u001b[A\n",
      "Epoch 1/3:  75%|███████▌  | 280/372 [12:58<05:00,  3.27s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  76%|███████▌  | 281/372 [12:58<04:09,  2.74s/it, loss=0.129]\u001b[A\n",
      "Epoch 1/3:  76%|███████▌  | 281/372 [13:00<04:09,  2.74s/it, loss=0.136]\u001b[A\n",
      "Epoch 1/3:  76%|███████▌  | 282/372 [13:00<03:33,  2.37s/it, loss=0.136]\u001b[A\n",
      "Epoch 1/3:  76%|███████▌  | 282/372 [13:01<03:33,  2.37s/it, loss=0.1]  \u001b[A\n",
      "Epoch 1/3:  76%|███████▌  | 283/372 [13:01<03:07,  2.11s/it, loss=0.1]\u001b[A\n",
      "Epoch 1/3:  76%|███████▌  | 283/372 [13:03<03:07,  2.11s/it, loss=0.117]\u001b[A\n",
      "Epoch 1/3:  76%|███████▋  | 284/372 [13:03<02:49,  1.93s/it, loss=0.117]\u001b[A\n",
      "Epoch 1/3:  76%|███████▋  | 284/372 [13:04<02:49,  1.93s/it, loss=0.118]\u001b[A\n",
      "Epoch 1/3:  77%|███████▋  | 285/372 [13:04<02:37,  1.81s/it, loss=0.118]\u001b[A\n",
      "Epoch 1/3:  77%|███████▋  | 285/372 [13:06<02:37,  1.81s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  77%|███████▋  | 286/372 [13:06<02:27,  1.72s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  77%|███████▋  | 286/372 [13:07<02:27,  1.72s/it, loss=0.163]\u001b[A\n",
      "Epoch 1/3:  77%|███████▋  | 287/372 [13:07<02:21,  1.66s/it, loss=0.163]\u001b[A\n",
      "Epoch 1/3:  77%|███████▋  | 287/372 [13:09<02:21,  1.66s/it, loss=0.0899]\u001b[A\n",
      "Epoch 1/3:  77%|███████▋  | 288/372 [13:09<02:16,  1.63s/it, loss=0.0899]\u001b[A\n",
      "Epoch 1/3:  77%|███████▋  | 288/372 [13:10<02:16,  1.63s/it, loss=0.111] \u001b[A\n",
      "Epoch 1/3:  78%|███████▊  | 289/372 [13:10<02:12,  1.59s/it, loss=0.111]\u001b[A\n",
      "Epoch 1/3:  78%|███████▊  | 289/372 [13:12<02:12,  1.59s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  78%|███████▊  | 290/372 [13:12<02:08,  1.57s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  78%|███████▊  | 290/372 [13:14<02:08,  1.57s/it, loss=0.0953]\u001b[A\n",
      "Epoch 1/3:  78%|███████▊  | 291/372 [13:14<02:06,  1.56s/it, loss=0.0953]\u001b[A\n",
      "Epoch 1/3:  78%|███████▊  | 291/372 [13:15<02:06,  1.56s/it, loss=0.106] \u001b[A\n",
      "Epoch 1/3:  78%|███████▊  | 292/372 [13:15<02:05,  1.57s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  78%|███████▊  | 292/372 [13:17<02:05,  1.57s/it, loss=0.101]\u001b[A\n",
      "Epoch 1/3:  79%|███████▉  | 293/372 [13:17<02:02,  1.56s/it, loss=0.101]\u001b[A\n",
      "Epoch 1/3:  79%|███████▉  | 293/372 [13:21<02:02,  1.56s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  79%|███████▉  | 294/372 [13:21<03:08,  2.42s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  79%|███████▉  | 294/372 [13:23<03:08,  2.42s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  79%|███████▉  | 295/372 [13:23<02:45,  2.15s/it, loss=0.137]\u001b[A\n",
      "Epoch 1/3:  79%|███████▉  | 295/372 [13:24<02:45,  2.15s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  80%|███████▉  | 296/372 [13:24<02:29,  1.96s/it, loss=0.107]\u001b[A\n",
      "Epoch 1/3:  80%|███████▉  | 296/372 [13:26<02:29,  1.96s/it, loss=0.0802]\u001b[A\n",
      "Epoch 1/3:  80%|███████▉  | 297/372 [13:26<02:17,  1.83s/it, loss=0.0802]\u001b[A\n",
      "Epoch 1/3:  80%|███████▉  | 297/372 [13:27<02:17,  1.83s/it, loss=0.115] \u001b[A\n",
      "Epoch 1/3:  80%|████████  | 298/372 [13:27<02:08,  1.74s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  80%|████████  | 298/372 [13:29<02:08,  1.74s/it, loss=0.0862]\u001b[A\n",
      "Epoch 1/3:  80%|████████  | 299/372 [13:29<02:02,  1.67s/it, loss=0.0862]\u001b[A\n",
      "Epoch 1/3:  80%|████████  | 299/372 [13:30<02:02,  1.67s/it, loss=0.17]  \u001b[A\n",
      "Epoch 1/3:  81%|████████  | 300/372 [13:30<01:56,  1.62s/it, loss=0.17]\u001b[A\n",
      "Epoch 1/3:  81%|████████  | 300/372 [13:32<01:56,  1.62s/it, loss=0.145]\u001b[A\n",
      "Epoch 1/3:  81%|████████  | 301/372 [13:32<01:52,  1.59s/it, loss=0.145]\u001b[A\n",
      "Epoch 1/3:  81%|████████  | 301/372 [13:35<01:52,  1.59s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  81%|████████  | 302/372 [13:35<02:28,  2.12s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  81%|████████  | 302/372 [13:37<02:28,  2.12s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  81%|████████▏ | 303/372 [13:37<02:13,  1.94s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  81%|████████▏ | 303/372 [13:38<02:13,  1.94s/it, loss=0.0952]\u001b[A\n",
      "Epoch 1/3:  82%|████████▏ | 304/372 [13:38<02:03,  1.81s/it, loss=0.0952]\u001b[A\n",
      "Epoch 1/3:  82%|████████▏ | 304/372 [13:40<02:03,  1.81s/it, loss=0.159] \u001b[A\n",
      "Epoch 1/3:  82%|████████▏ | 305/372 [13:40<01:55,  1.72s/it, loss=0.159]\u001b[A\n",
      "Epoch 1/3:  82%|████████▏ | 305/372 [13:41<01:55,  1.72s/it, loss=0.11] \u001b[A\n",
      "Epoch 1/3:  82%|████████▏ | 306/372 [13:41<01:49,  1.66s/it, loss=0.11]\u001b[A\n",
      "Epoch 1/3:  82%|████████▏ | 306/372 [13:43<01:49,  1.66s/it, loss=0.111]\u001b[A\n",
      "Epoch 1/3:  83%|████████▎ | 307/372 [13:43<01:44,  1.61s/it, loss=0.111]\u001b[A\n",
      "Epoch 1/3:  83%|████████▎ | 307/372 [13:44<01:44,  1.61s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  83%|████████▎ | 308/372 [13:44<01:41,  1.58s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  83%|████████▎ | 308/372 [13:46<01:41,  1.58s/it, loss=0.0943]\u001b[A\n",
      "Epoch 1/3:  83%|████████▎ | 309/372 [13:46<01:38,  1.56s/it, loss=0.0943]\u001b[A\n",
      "Epoch 1/3:  83%|████████▎ | 309/372 [13:47<01:38,  1.56s/it, loss=0.113] \u001b[A\n",
      "Epoch 1/3:  83%|████████▎ | 310/372 [13:47<01:36,  1.55s/it, loss=0.113]\u001b[A\n",
      "Epoch 1/3:  83%|████████▎ | 310/372 [13:49<01:36,  1.55s/it, loss=0.13] \u001b[A\n",
      "Epoch 1/3:  84%|████████▎ | 311/372 [13:49<01:34,  1.54s/it, loss=0.13]\u001b[A\n",
      "Epoch 1/3:  84%|████████▎ | 311/372 [13:50<01:34,  1.54s/it, loss=0.0972]\u001b[A\n",
      "Epoch 1/3:  84%|████████▍ | 312/372 [13:50<01:32,  1.54s/it, loss=0.0972]\u001b[A\n",
      "Epoch 1/3:  84%|████████▍ | 312/372 [13:52<01:32,  1.54s/it, loss=0.128] \u001b[A\n",
      "Epoch 1/3:  84%|████████▍ | 313/372 [13:52<01:30,  1.53s/it, loss=0.128]\u001b[A\n",
      "Epoch 1/3:  84%|████████▍ | 313/372 [13:53<01:30,  1.53s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  84%|████████▍ | 314/372 [13:53<01:28,  1.53s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  84%|████████▍ | 314/372 [13:55<01:28,  1.53s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  85%|████████▍ | 315/372 [13:55<01:26,  1.53s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  85%|████████▍ | 315/372 [13:56<01:26,  1.53s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  85%|████████▍ | 316/372 [13:56<01:25,  1.52s/it, loss=0.138]\u001b[A\n",
      "Epoch 1/3:  85%|████████▍ | 316/372 [13:58<01:25,  1.52s/it, loss=0.101]\u001b[A\n",
      "Epoch 1/3:  85%|████████▌ | 317/372 [13:58<01:23,  1.52s/it, loss=0.101]\u001b[A\n",
      "Epoch 1/3:  85%|████████▌ | 317/372 [13:59<01:23,  1.52s/it, loss=0.0963]\u001b[A\n",
      "Epoch 1/3:  85%|████████▌ | 318/372 [13:59<01:21,  1.51s/it, loss=0.0963]\u001b[A\n",
      "Epoch 1/3:  85%|████████▌ | 318/372 [14:01<01:21,  1.51s/it, loss=0.157] \u001b[A\n",
      "Epoch 1/3:  86%|████████▌ | 319/372 [14:01<01:20,  1.52s/it, loss=0.157]\u001b[A\n",
      "Epoch 1/3:  86%|████████▌ | 319/372 [14:02<01:20,  1.52s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  86%|████████▌ | 320/372 [14:02<01:18,  1.52s/it, loss=0.126]\u001b[A\n",
      "Epoch 1/3:  86%|████████▌ | 320/372 [14:04<01:18,  1.52s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  86%|████████▋ | 321/372 [14:04<01:17,  1.53s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  86%|████████▋ | 321/372 [14:05<01:17,  1.53s/it, loss=0.16] \u001b[A\n",
      "Epoch 1/3:  87%|████████▋ | 322/372 [14:05<01:16,  1.52s/it, loss=0.16]\u001b[A\n",
      "Epoch 1/3:  87%|████████▋ | 322/372 [14:07<01:16,  1.52s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  87%|████████▋ | 323/372 [14:07<01:14,  1.52s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  87%|████████▋ | 323/372 [14:08<01:14,  1.52s/it, loss=0.101]\u001b[A\n",
      "Epoch 1/3:  87%|████████▋ | 324/372 [14:08<01:12,  1.51s/it, loss=0.101]\u001b[A\n",
      "Epoch 1/3:  87%|████████▋ | 324/372 [14:10<01:12,  1.51s/it, loss=0.102]\u001b[A\n",
      "Epoch 1/3:  87%|████████▋ | 325/372 [14:10<01:10,  1.51s/it, loss=0.102]\u001b[A\n",
      "Epoch 1/3:  87%|████████▋ | 325/372 [14:11<01:10,  1.51s/it, loss=0.156]\u001b[A\n",
      "Epoch 1/3:  88%|████████▊ | 326/372 [14:11<01:09,  1.51s/it, loss=0.156]\u001b[A\n",
      "Epoch 1/3:  88%|████████▊ | 326/372 [14:13<01:09,  1.51s/it, loss=0.147]\u001b[A\n",
      "Epoch 1/3:  88%|████████▊ | 327/372 [14:13<01:08,  1.51s/it, loss=0.147]\u001b[A\n",
      "Epoch 1/3:  88%|████████▊ | 327/372 [14:14<01:08,  1.51s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:  88%|████████▊ | 328/372 [14:14<01:06,  1.51s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:  88%|████████▊ | 328/372 [14:16<01:06,  1.51s/it, loss=0.0879]\u001b[A\n",
      "Epoch 1/3:  88%|████████▊ | 329/372 [14:16<01:04,  1.51s/it, loss=0.0879]\u001b[A\n",
      "Epoch 1/3:  88%|████████▊ | 329/372 [14:17<01:04,  1.51s/it, loss=0.114] \u001b[A\n",
      "Epoch 1/3:  89%|████████▊ | 330/372 [14:17<01:03,  1.51s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  89%|████████▊ | 330/372 [14:19<01:03,  1.51s/it, loss=0.087]\u001b[A\n",
      "Epoch 1/3:  89%|████████▉ | 331/372 [14:19<01:01,  1.51s/it, loss=0.087]\u001b[A\n",
      "Epoch 1/3:  89%|████████▉ | 331/372 [14:21<01:01,  1.51s/it, loss=0.171]\u001b[A\n",
      "Epoch 1/3:  89%|████████▉ | 332/372 [14:21<01:00,  1.51s/it, loss=0.171]\u001b[A\n",
      "Epoch 1/3:  89%|████████▉ | 332/372 [14:22<01:00,  1.51s/it, loss=0.167]\u001b[A\n",
      "Epoch 1/3:  90%|████████▉ | 333/372 [14:22<00:58,  1.51s/it, loss=0.167]\u001b[A\n",
      "Epoch 1/3:  90%|████████▉ | 333/372 [14:24<00:58,  1.51s/it, loss=0.133]\u001b[A\n",
      "Epoch 1/3:  90%|████████▉ | 334/372 [14:24<00:57,  1.51s/it, loss=0.133]\u001b[A\n",
      "Epoch 1/3:  90%|████████▉ | 334/372 [14:25<00:57,  1.51s/it, loss=0.0795]\u001b[A\n",
      "Epoch 1/3:  90%|█████████ | 335/372 [14:25<00:56,  1.52s/it, loss=0.0795]\u001b[A\n",
      "Epoch 1/3:  90%|█████████ | 335/372 [14:27<00:56,  1.52s/it, loss=0.124] \u001b[A\n",
      "Epoch 1/3:  90%|█████████ | 336/372 [14:27<00:54,  1.51s/it, loss=0.124]\u001b[A\n",
      "Epoch 1/3:  90%|█████████ | 336/372 [14:28<00:54,  1.51s/it, loss=0.105]\u001b[A\n",
      "Epoch 1/3:  91%|█████████ | 337/372 [14:28<00:52,  1.51s/it, loss=0.105]\u001b[A\n",
      "Epoch 1/3:  91%|█████████ | 337/372 [14:30<00:52,  1.51s/it, loss=0.0965]\u001b[A\n",
      "Epoch 1/3:  91%|█████████ | 338/372 [14:30<00:51,  1.51s/it, loss=0.0965]\u001b[A\n",
      "Epoch 1/3:  91%|█████████ | 338/372 [14:31<00:51,  1.51s/it, loss=0.166] \u001b[A\n",
      "Epoch 1/3:  91%|█████████ | 339/372 [14:31<00:49,  1.51s/it, loss=0.166]\u001b[A\n",
      "Epoch 1/3:  91%|█████████ | 339/372 [14:33<00:49,  1.51s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  91%|█████████▏| 340/372 [14:33<00:48,  1.51s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  91%|█████████▏| 340/372 [14:34<00:48,  1.51s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  92%|█████████▏| 341/372 [14:34<00:46,  1.51s/it, loss=0.115]\u001b[A\n",
      "Epoch 1/3:  92%|█████████▏| 341/372 [14:36<00:46,  1.51s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  92%|█████████▏| 342/372 [14:36<00:52,  1.76s/it, loss=0.119]\u001b[A\n",
      "Epoch 1/3:  92%|█████████▏| 342/372 [14:38<00:52,  1.76s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  92%|█████████▏| 343/372 [14:38<00:48,  1.68s/it, loss=0.122]\u001b[A\n",
      "Epoch 1/3:  92%|█████████▏| 343/372 [14:39<00:48,  1.68s/it, loss=0.118]\u001b[A\n",
      "Epoch 1/3:  92%|█████████▏| 344/372 [14:39<00:45,  1.63s/it, loss=0.118]\u001b[A\n",
      "Epoch 1/3:  92%|█████████▏| 344/372 [14:41<00:45,  1.63s/it, loss=0.161]\u001b[A\n",
      "Epoch 1/3:  93%|█████████▎| 345/372 [14:41<00:43,  1.60s/it, loss=0.161]\u001b[A\n",
      "Epoch 1/3:  93%|█████████▎| 345/372 [14:43<00:43,  1.60s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  93%|█████████▎| 346/372 [14:43<00:40,  1.57s/it, loss=0.141]\u001b[A\n",
      "Epoch 1/3:  93%|█████████▎| 346/372 [14:44<00:40,  1.57s/it, loss=0.151]\u001b[A\n",
      "Epoch 1/3:  93%|█████████▎| 347/372 [14:44<00:38,  1.55s/it, loss=0.151]\u001b[A\n",
      "Epoch 1/3:  93%|█████████▎| 347/372 [14:46<00:38,  1.55s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  94%|█████████▎| 348/372 [14:46<00:36,  1.54s/it, loss=0.125]\u001b[A\n",
      "Epoch 1/3:  94%|█████████▎| 348/372 [14:47<00:36,  1.54s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  94%|█████████▍| 349/372 [14:47<00:34,  1.52s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  94%|█████████▍| 349/372 [14:51<00:34,  1.52s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  94%|█████████▍| 350/372 [14:51<00:48,  2.20s/it, loss=0.139]\u001b[A\n",
      "Epoch 1/3:  94%|█████████▍| 350/372 [14:52<00:48,  2.20s/it, loss=0.167]\u001b[A\n",
      "Epoch 1/3:  94%|█████████▍| 351/372 [14:52<00:41,  1.99s/it, loss=0.167]\u001b[A\n",
      "Epoch 1/3:  94%|█████████▍| 351/372 [14:54<00:41,  1.99s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  95%|█████████▍| 352/372 [14:54<00:36,  1.84s/it, loss=0.121]\u001b[A\n",
      "Epoch 1/3:  95%|█████████▍| 352/372 [14:55<00:36,  1.84s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  95%|█████████▍| 353/372 [14:55<00:32,  1.74s/it, loss=0.116]\u001b[A\n",
      "Epoch 1/3:  95%|█████████▍| 353/372 [14:57<00:32,  1.74s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  95%|█████████▌| 354/372 [14:57<00:29,  1.67s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  95%|█████████▌| 354/372 [14:58<00:29,  1.67s/it, loss=0.13] \u001b[A\n",
      "Epoch 1/3:  95%|█████████▌| 355/372 [14:58<00:27,  1.62s/it, loss=0.13]\u001b[A\n",
      "Epoch 1/3:  95%|█████████▌| 355/372 [15:00<00:27,  1.62s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  96%|█████████▌| 356/372 [15:00<00:25,  1.58s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  96%|█████████▌| 356/372 [15:01<00:25,  1.58s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  96%|█████████▌| 357/372 [15:01<00:23,  1.56s/it, loss=0.109]\u001b[A\n",
      "Epoch 1/3:  96%|█████████▌| 357/372 [15:04<00:23,  1.56s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  96%|█████████▌| 358/372 [15:04<00:28,  2.01s/it, loss=0.112]\u001b[A\n",
      "Epoch 1/3:  96%|█████████▌| 358/372 [15:06<00:28,  2.01s/it, loss=0.104]\u001b[A\n",
      "Epoch 1/3:  97%|█████████▋| 359/372 [15:06<00:24,  1.86s/it, loss=0.104]\u001b[A\n",
      "Epoch 1/3:  97%|█████████▋| 359/372 [15:07<00:24,  1.86s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  97%|█████████▋| 360/372 [15:07<00:20,  1.75s/it, loss=0.155]\u001b[A\n",
      "Epoch 1/3:  97%|█████████▋| 360/372 [15:09<00:20,  1.75s/it, loss=0.124]\u001b[A\n",
      "Epoch 1/3:  97%|█████████▋| 361/372 [15:09<00:18,  1.68s/it, loss=0.124]\u001b[A\n",
      "Epoch 1/3:  97%|█████████▋| 361/372 [15:10<00:18,  1.68s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  97%|█████████▋| 362/372 [15:10<00:16,  1.62s/it, loss=0.106]\u001b[A\n",
      "Epoch 1/3:  97%|█████████▋| 362/372 [15:12<00:16,  1.62s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  98%|█████████▊| 363/372 [15:12<00:14,  1.59s/it, loss=0.135]\u001b[A\n",
      "Epoch 1/3:  98%|█████████▊| 363/372 [15:13<00:14,  1.59s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  98%|█████████▊| 364/372 [15:13<00:12,  1.57s/it, loss=0.114]\u001b[A\n",
      "Epoch 1/3:  98%|█████████▊| 364/372 [15:15<00:12,  1.57s/it, loss=0.0907]\u001b[A\n",
      "Epoch 1/3:  98%|█████████▊| 365/372 [15:15<00:10,  1.56s/it, loss=0.0907]\u001b[A\n",
      "Epoch 1/3:  98%|█████████▊| 365/372 [15:16<00:10,  1.56s/it, loss=0.168] \u001b[A\n",
      "Epoch 1/3:  98%|█████████▊| 366/372 [15:16<00:09,  1.55s/it, loss=0.168]\u001b[A\n",
      "Epoch 1/3:  98%|█████████▊| 366/372 [15:18<00:09,  1.55s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  99%|█████████▊| 367/372 [15:18<00:07,  1.54s/it, loss=0.127]\u001b[A\n",
      "Epoch 1/3:  99%|█████████▊| 367/372 [15:19<00:07,  1.54s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:  99%|█████████▉| 368/372 [15:19<00:06,  1.53s/it, loss=0.132]\u001b[A\n",
      "Epoch 1/3:  99%|█████████▉| 368/372 [15:21<00:06,  1.53s/it, loss=0.187]\u001b[A\n",
      "Epoch 1/3:  99%|█████████▉| 369/372 [15:21<00:04,  1.53s/it, loss=0.187]\u001b[A\n",
      "Epoch 1/3:  99%|█████████▉| 369/372 [15:22<00:04,  1.53s/it, loss=0.111]\u001b[A\n",
      "Epoch 1/3:  99%|█████████▉| 370/372 [15:22<00:03,  1.51s/it, loss=0.111]\u001b[A\n",
      "Epoch 1/3:  99%|█████████▉| 370/372 [15:24<00:03,  1.51s/it, loss=0.165]\u001b[A\n",
      "Epoch 1/3: 100%|█████████▉| 371/372 [15:24<00:01,  1.51s/it, loss=0.165]\u001b[A\n",
      "Epoch 1/3: 100%|█████████▉| 371/372 [15:25<00:01,  1.51s/it, loss=0.102]\u001b[A\n",
      "Epoch 1/3: 100%|██████████| 372/372 [15:26<00:00,  2.49s/it, loss=0.102]\n",
      "Epoch 2/3: 100%|██████████| 372/372 [09:19<00:00,  1.50s/it, loss=0.163]\n",
      "Epoch 3/3: 100%|██████████| 372/372 [09:19<00:00,  1.50s/it, loss=0.121]\n",
      "Validating...: 100%|██████████| 107/107 [03:31<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - val_acc=0.7974, f1=0.7977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7973607038123167, 0.7976573938506588)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6\n",
    "train_variant(1, df_train, df_val, tokenizer, img_tf, device)\n",
    "#need re-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1919998,
     "status": "ok",
     "timestamp": 1752833279233,
     "user": {
      "displayName": "Thanh Sang Lê",
      "userId": "09771502319100460389"
     },
     "user_tz": -420
    },
    "id": "aQQ4oxyBuDzp",
    "outputId": "e544c3b9-c7e1-4bb0-ed52-67ff66252f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training variant 2: {'bs': 32, 'lr': 0.0002, 'fusion': 'gated', 'loss': 'focal'} | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 372/372 [10:15<00:00,  1.66s/it, loss=0.115]\n",
      "Epoch 2/3: 100%|██████████| 372/372 [09:29<00:00,  1.53s/it, loss=0.103]\n",
      "Epoch 3/3: 100%|██████████| 372/372 [09:29<00:00,  1.53s/it, loss=0.102]\n",
      "Validating...: 100%|██████████| 107/107 [02:38<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - val_acc=0.8147, f1=0.8199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8146627565982405, 0.81994301994302)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7\n",
    "train_variant(2, df_train, df_val, tokenizer, img_tf, device)\n",
    "#need re-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "e9c8e42b144d470397a3a99e232d2aa3",
      "01b2a31eaae043a29ed88008d30229bd",
      "1b52e43289c340379d08305b5c5fdd83",
      "9dd14e5b765c420192975fc498c0f188",
      "f47deed51c0a4e8c8d2a771b9283a2d5",
      "7731e16cdeaf48ff86ed19a679e7f0e8",
      "5c33dc22f6894949a09d85a48e85da17",
      "9ac6258fe5444955b9b685b8ec5908d6",
      "890b18f1eddf43f9813c1a862172baba",
      "a487c71781a34b0dbb5a8450dc3899ab",
      "2f9d504de0734ef499f88298f8522364",
      "4be1c2d2a5c247faacc4556feb467f69",
      "257b536ae1ea465f9f684a108ad46842",
      "34894b79532347dba799e242a2ee16fd",
      "a40c1f7012b14b4bbd3e34c60e46c22c",
      "4a2e4661cd7f4f9fbb90126c2e0fcd96",
      "c3c0eea3d0474769b26062564a8ada41",
      "c39ac8fa2c6040f59a2c04a04947415d",
      "fee25f53c4604096bb785f037948ff98",
      "0b1791968be54f6db4ee7c11653ced93",
      "abdfeb21144a4ab1ab578075cbb31be1",
      "c138fe3c1e6440489b998389189e57bc",
      "889e1bfc911b41b29a9d3432251c186d",
      "5bd496b54ad2497c81e8d5c69b418e6d",
      "5453785cd9a948aebab3a69797738976",
      "7c109a75ed984d40899cefe5165798ed",
      "c5bbb5a4c6d14165b1154716f251b03b",
      "25ce4fe8cf5948b292291b449f3ebfdc",
      "fad3e5cea80b40e3a2528035e3e2658c",
      "bfc3e7babafd4624984627cbdf9812e3",
      "b52ae16b0e0747ea96cd037cf1092242",
      "e1f936b942fb41648538919723c4a83d",
      "b8ec28cd9ceb47ec82698f02d3619f67",
      "da0a5f8579624fc2b3c9a71f4dd1885c",
      "71d90bdf899944eb9b8374d94b3614c5",
      "00603b234755469ea30eae5b84a97444",
      "204586158cbd417c8d51c86d484f5448",
      "f42fb30a4d90460295c94a76f76124aa",
      "790c807ec6c04fbd9f26e05603ee3f5a",
      "8cb38f87e7a34044915867cde39cf353",
      "5ca5f3b6f1c04e8487f20afd2825c82c",
      "055d239c5c8a4dca996f06b8f3d17de0",
      "54df9d4d29924b9090bf0113c4c744ca",
      "bd6bb0634f5e4ce9a37e98053bb0f8db"
     ]
    },
    "executionInfo": {
     "elapsed": 3079737,
     "status": "ok",
     "timestamp": 1752837037146,
     "user": {
      "displayName": "Thanh Sang Lê",
      "userId": "09771502319100460389"
     },
     "user_tz": -420
    },
    "id": "em70KJ-iuFD6",
    "outputId": "43951fdd-9a20-45b5-d472-5a70e48d564c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training variant 3: {'bs': 32, 'lr': 0.0005, 'fusion': 'gated', 'loss': 'bce'} | \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c8e42b144d470397a3a99e232d2aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be1c2d2a5c247faacc4556feb467f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889e1bfc911b41b29a9d3432251c186d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch 1/3:   0%|          | 0/372 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0a5f8579624fc2b3c9a71f4dd1885c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 372/372 [25:34<00:00,  4.12s/it, loss=0.489]\n",
      "Epoch 2/3: 100%|██████████| 372/372 [09:34<00:00,  1.54s/it, loss=0.46]\n",
      "Epoch 3/3: 100%|██████████| 372/372 [09:33<00:00,  1.54s/it, loss=0.531]\n",
      "Validating...: 100%|██████████| 107/107 [06:12<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - val_acc=0.8082, f1=0.7922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8082111436950147, 0.7922490470139771)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8\n",
    "train_variant(3, df_train, df_val, tokenizer, img_tf, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2848623,
     "status": "ok",
     "timestamp": 1752853173468,
     "user": {
      "displayName": "Thanh Sang Lê",
      "userId": "09771502319100460389"
     },
     "user_tz": -420
    },
    "id": "NGIG8B7auGVH",
    "outputId": "fe2e5c39-d576-4338-998f-2b5435bb1eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training variant 4: {'bs': 32, 'lr': 0.0002, 'fusion': 'gated', 'loss': 'focal'} | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 372/372 [22:39<00:00,  3.66s/it, loss=0.106]\n",
      "Epoch 2/3: 100%|██████████| 372/372 [09:28<00:00,  1.53s/it, loss=0.0914]\n",
      "Epoch 3/3: 100%|██████████| 372/372 [09:27<00:00,  1.52s/it, loss=0.108]\n",
      "Validating...: 100%|██████████| 107/107 [05:45<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - val_acc=0.8067, f1=0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8067448680351906, 0.8090408577223993)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9\n",
    "train_variant(4, df_train, df_val, tokenizer, img_tf, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load các model tốt nhất sau huấn luyện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQ58Iekzt_Ev"
   },
   "outputs": [],
   "source": [
    "#10\n",
    "# Sau khi đã train, bạn chọn tay 3 model tốt nhất:\n",
    "chosen = [2, 3, 4] # change\n",
    "models = load_models(chosen, df_train, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1753330916708,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "EqydVTm-iV-c",
    "outputId": "51bb23c0-da09-4f29-da0a-01167b8a9885"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33872446, 0.33146436, 0.32981118])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11\n",
    "scores = [0.8147, 0.8082, 0.8067] #acc1, acc2, acc3, acc4, acc5\n",
    "\n",
    "def softmax(x, tau=0.05  ):\n",
    "    x = np.array(x)\n",
    "    e = np.exp(x / tau)\n",
    "    return e / e.sum()\n",
    "weights = softmax(scores, tau=0.3)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eval on Full Test-Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 499240,
     "status": "ok",
     "timestamp": 1752980570871,
     "user": {
      "displayName": "Thanh Sang Lê",
      "userId": "09771502319100460389"
     },
     "user_tz": -420
    },
    "id": "R7BqyvIhrHXN",
    "outputId": "963397b8-b342-49d2-b6e1-7c110b5544a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running full-set ensemble evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Full-set → acc=0.8283, f1=0.8273, recall=0.8259, PR-AUC=0.9069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.828253223915592,\n",
       " 'f1': 0.8273423688862699,\n",
       " 'recall': 0.8258823529411765,\n",
       " 'pr_auc': np.float64(0.9069224687695836)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11\n",
    "#df_test = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/df_test.pkl\")\n",
    "\n",
    "full_eval_run(df_test, models, weights, tokenizer, img_tf, device, bs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test few-shot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18033,
     "status": "ok",
     "timestamp": 1752855777985,
     "user": {
      "displayName": "Thanh Sang Lê",
      "userId": "09771502319100460389"
     },
     "user_tz": -420
    },
    "id": "wVxpICsdDF3d",
    "outputId": "44dea7c5-c475-494e-aacb-f145e9904bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running few-shot experiment with k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 0/2: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "Model 1/2: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "Model 2/2: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  k=5 → acc=0.8000, f1=0.7500\n",
      "Running few-shot experiment with k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 0/2: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Model 1/2: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Model 2/2: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  k=10 → acc=0.8000, f1=0.7778\n",
      "Running few-shot experiment with k=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 0/2: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n",
      "Model 1/2: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n",
      "Model 2/2: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  k=20 → acc=0.8500, f1=0.8421\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "results = []\n",
    "for k in [5, 10, 20]:\n",
    "    fewshot_df = sample_k_shot(df_test, k=k, seed=42)  # hoặc random seed\n",
    "    result = fewshot_run(fewshot_df, models, weights, k, tokenizer, img_tf, device, bs=32)\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_pickle(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/results_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1753330277967,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "lQbgd015DtoU",
    "outputId": "c4e841a3-8870-47a0-c788-571c38763117"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 5,\n        \"max\": 20,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          10,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02886751345948125,\n        \"min\": 0.8,\n        \"max\": 0.85,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.85,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.047245828413708994,\n        \"min\": 0.75,\n        \"max\": 0.8421052631578947,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.75,\n          0.7777777777777778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10000000000000003,\n        \"min\": 0.6,\n        \"max\": 0.8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6,\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019983353476779105,\n        \"min\": 0.924626762126762,\n        \"max\": 0.9639486260578013,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9380952380952381,\n          0.924626762126762\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "results_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-865720b3-9656-471f-ab85-07ef07f23986\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.924627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.963949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-865720b3-9656-471f-ab85-07ef07f23986')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-865720b3-9656-471f-ab85-07ef07f23986 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-865720b3-9656-471f-ab85-07ef07f23986');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-58edae2c-5a14-4599-83a1-a48174883870\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58edae2c-5a14-4599-83a1-a48174883870')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-58edae2c-5a14-4599-83a1-a48174883870 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_6fe65393-cd51-43f6-b36d-bc31cdca818f\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_6fe65393-cd51-43f6-b36d-bc31cdca818f button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('results_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    k   acc        f1  recall    pr_auc\n",
       "0   5  0.80  0.750000     0.6  0.938095\n",
       "1  10  0.80  0.777778     0.7  0.924627\n",
       "2  20  0.85  0.842105     0.8  0.963949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#13\n",
    "results_df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/results_new.pkl\")\n",
    "display(results_df)\n",
    "plot_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb6H99FNt3a9"
   },
   "source": [
    "**Test 1 sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1753330981335,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "u9hj0mrToWCd",
    "outputId": "69a31134-e4f1-4e1b-d4e1-06cd04349f26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1309</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>article_url</th>\n",
       "      <td>https://www.thesun.ie/tv/15009142/country-hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_title</th>\n",
       "      <td>Incredible country house which features in ico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_description</th>\n",
       "      <td>A FAMOUS mansion where a hit British TV show w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumbnail</th>\n",
       "      <td>/content/drive/MyDrive/Colab Notebooks/NLP/pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "article_url            https://www.thesun.ie/tv/15009142/country-hous...\n",
       "article_title          Incredible country house which features in ico...\n",
       "article_description    A FAMOUS mansion where a hit British TV show w...\n",
       "thumbnail              /content/drive/MyDrive/Colab Notebooks/NLP/pro...\n",
       "label                                                                  1\n",
       "Name: 1309, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1row = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/NLP/project/df_test.pkl\")\n",
    "\n",
    "row = df_1row.sample(n=1, random_state=random.randint(0, 99999)).iloc[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1753331721691,
     "user": {
      "displayName": "Minh Duy",
      "userId": "09569497878950308983"
     },
     "user_tz": -420
    },
    "id": "c_5shnh3tfsk",
    "outputId": "d2fb26e0-2f48-4103-a41d-554735dc8598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth: 1\n",
      "Predicted   : 1\n"
     ]
    }
   ],
   "source": [
    "# ---- 1. Tiền xử lý text ----\n",
    "encoded = tokenizer(\n",
    "    row['article_title'], row['article_description'],\n",
    "    padding='max_length', truncation=True,\n",
    "    max_length=128, return_tensors='pt'\n",
    ")\n",
    "input_ids = encoded['input_ids'].to(device)\n",
    "attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "# ---- 2. Tiền xử lý ảnh ----\n",
    "try:\n",
    "    img = Image.open(row['thumbnail']).convert('RGB')\n",
    "except:\n",
    "    img = Image.new('RGB', (224, 224), (0, 0, 0))  # fallback nếu lỗi ảnh\n",
    "image_tensor = img_tf(img).unsqueeze(0).to(device)\n",
    "\n",
    "# ---- 3. Chuẩn bị title ----\n",
    "title = row['article_title']\n",
    "titles = [title]  # batch dạng list\n",
    "\n",
    "# ---- 4. Chạy từng model trong ensemble ----\n",
    "probs = []\n",
    "for m in models:\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        p = m(input_ids, attention_mask, image_tensor, titles).sigmoid().cpu()\n",
    "        probs.append(p.squeeze(0))  # (1,) → ()\n",
    "\n",
    "# ---- 5. Voting + Kết quả ----\n",
    "bin_preds = [(p > 0.5).int() for p in probs]\n",
    "votes = sum(p * w for p, w in zip(bin_preds, weights))\n",
    "final_pred = int((votes > 0.5).item())\n",
    "true_label = int(row['label'])\n",
    "\n",
    "\n",
    "# Tính voting\n",
    "bin_preds = [(p > 0.5).int() for p in probs]\n",
    "votes = sum(p * w for p, w in zip(bin_preds, weights))\n",
    "final_pred = int((votes > 0.5).item())\n",
    "true_label = int(row['label'])\n",
    "\n",
    "# So sánh\n",
    "print(f\"Ground-truth: {true_label}\")\n",
    "print(f\"Predicted   : {final_pred}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
